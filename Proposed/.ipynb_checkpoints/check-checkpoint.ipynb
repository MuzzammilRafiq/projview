{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path as osp\n",
    "import glob\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "import RRDBNet_arch as arch "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = 'models/RRDB_ESRGAN_x4.pth'  # models/RRDB_ESRGAN_x4.pth OR models/RRDB_PSNR_x4.pth\n",
    "device = torch.device('cpu')  # if you want to run on CPU, change 'cuda' -> cpu\n",
    "test_img_folder = 'archive/glioma_tumor/*'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model path models/RRDB_ESRGAN_x4.pth. \n",
      "Testing...\n"
     ]
    }
   ],
   "source": [
    "model = arch.RRDBNet(3, 3, 64, 23, gc=32)\n",
    "model.load_state_dict(torch.load(model_path), strict=True)\n",
    "model.eval()\n",
    "model = model.to(device)\n",
    "\n",
    "print('Model path {:s}. \\nTesting...'.format(model_path))\n",
    "\n",
    "idx = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 gg (1)\n",
      "2 gg (10)\n",
      "3 gg (100)\n",
      "4 gg (101)\n",
      "5 gg (102)\n",
      "6 gg (103)\n",
      "7 gg (104)\n",
      "8 gg (105)\n",
      "9 gg (106)\n",
      "10 gg (107)\n",
      "11 gg (108)\n",
      "12 gg (109)\n",
      "13 gg (11)\n",
      "14 gg (110)\n",
      "15 gg (111)\n",
      "16 gg (112)\n",
      "17 gg (113)\n",
      "18 gg (114)\n",
      "19 gg (115)\n",
      "20 gg (116)\n",
      "21 gg (117)\n",
      "22 gg (118)\n",
      "23 gg (119)\n",
      "24 gg (12)\n",
      "25 gg (120)\n",
      "26 gg (121)\n",
      "27 gg (122)\n",
      "28 gg (123)\n",
      "29 gg (124)\n",
      "30 gg (125)\n",
      "31 gg (126)\n",
      "32 gg (127)\n",
      "33 gg (128)\n",
      "34 gg (129)\n",
      "35 gg (13)\n",
      "36 gg (130)\n",
      "37 gg (131)\n",
      "38 gg (132)\n",
      "39 gg (133)\n",
      "40 gg (134)\n",
      "41 gg (135)\n",
      "42 gg (136)\n",
      "43 gg (137)\n",
      "44 gg (138)\n",
      "45 gg (139)\n",
      "46 gg (14)\n",
      "47 gg (140)\n",
      "48 gg (141)\n",
      "49 gg (142)\n",
      "50 gg (143)\n",
      "51 gg (144)\n",
      "52 gg (145)\n",
      "53 gg (146)\n",
      "54 gg (147)\n",
      "55 gg (148)\n",
      "56 gg (149)\n",
      "57 gg (15)\n",
      "58 gg (150)\n",
      "59 gg (151)\n",
      "60 gg (152)\n",
      "61 gg (153)\n",
      "62 gg (154)\n",
      "63 gg (155)\n",
      "64 gg (156)\n",
      "65 gg (157)\n",
      "66 gg (158)\n",
      "67 gg (159)\n",
      "68 gg (16)\n",
      "69 gg (160)\n",
      "70 gg (161)\n",
      "71 gg (162)\n",
      "72 gg (163)\n",
      "73 gg (164)\n",
      "74 gg (165)\n",
      "75 gg (166)\n",
      "76 gg (167)\n",
      "77 gg (168)\n",
      "78 gg (169)\n",
      "79 gg (17)\n",
      "80 gg (170)\n",
      "81 gg (171)\n",
      "82 gg (172)\n",
      "83 gg (173)\n",
      "84 gg (174)\n",
      "85 gg (175)\n",
      "86 gg (176)\n",
      "87 gg (177)\n",
      "88 gg (178)\n",
      "89 gg (179)\n",
      "90 gg (18)\n",
      "91 gg (180)\n",
      "92 gg (181)\n",
      "93 gg (182)\n",
      "94 gg (183)\n",
      "95 gg (184)\n",
      "96 gg (185)\n",
      "97 gg (186)\n",
      "98 gg (187)\n",
      "99 gg (188)\n",
      "100 gg (189)\n",
      "101 gg (19)\n",
      "102 gg (190)\n",
      "103 gg (191)\n",
      "104 gg (192)\n",
      "105 gg (193)\n",
      "106 gg (194)\n",
      "107 gg (195)\n",
      "108 gg (196)\n",
      "109 gg (197)\n",
      "110 gg (198)\n",
      "111 gg (199)\n",
      "112 gg (2)\n",
      "113 gg (20)\n",
      "114 gg (200)\n",
      "115 gg (201)\n",
      "116 gg (202)\n",
      "117 gg (203)\n",
      "118 gg (204)\n",
      "119 gg (205)\n",
      "120 gg (206)\n",
      "121 gg (207)\n",
      "122 gg (208)\n",
      "123 gg (209)\n",
      "124 gg (21)\n",
      "125 gg (210)\n",
      "126 gg (211)\n",
      "127 gg (212)\n",
      "128 gg (213)\n",
      "129 gg (214)\n",
      "130 gg (215)\n",
      "131 gg (216)\n",
      "132 gg (217)\n",
      "133 gg (218)\n",
      "134 gg (219)\n",
      "135 gg (22)\n",
      "136 gg (220)\n",
      "137 gg (221)\n",
      "138 gg (222)\n",
      "139 gg (223)\n",
      "140 gg (224)\n",
      "141 gg (225)\n",
      "142 gg (226)\n",
      "143 gg (227)\n",
      "144 gg (228)\n",
      "145 gg (229)\n",
      "146 gg (23)\n",
      "147 gg (230)\n",
      "148 gg (231)\n",
      "149 gg (232)\n",
      "150 gg (233)\n",
      "151 gg (234)\n",
      "152 gg (235)\n",
      "153 gg (236)\n",
      "154 gg (237)\n",
      "155 gg (238)\n",
      "156 gg (239)\n",
      "157 gg (24)\n",
      "158 gg (240)\n",
      "159 gg (241)\n",
      "160 gg (242)\n",
      "161 gg (243)\n",
      "162 gg (244)\n",
      "163 gg (245)\n",
      "164 gg (246)\n",
      "165 gg (247)\n",
      "166 gg (248)\n",
      "167 gg (249)\n",
      "168 gg (25)\n",
      "169 gg (250)\n",
      "170 gg (251)\n",
      "171 gg (252)\n",
      "172 gg (253)\n",
      "173 gg (254)\n",
      "174 gg (255)\n",
      "175 gg (256)\n",
      "176 gg (257)\n",
      "177 gg (258)\n",
      "178 gg (259)\n",
      "179 gg (26)\n",
      "180 gg (260)\n",
      "181 gg (261)\n",
      "182 gg (262)\n",
      "183 gg (263)\n",
      "184 gg (264)\n",
      "185 gg (265)\n",
      "186 gg (266)\n",
      "187 gg (267)\n",
      "188 gg (268)\n",
      "189 gg (269)\n",
      "190 gg (27)\n",
      "191 gg (270)\n",
      "192 gg (271)\n",
      "193 gg (272)\n",
      "194 gg (273)\n",
      "195 gg (274)\n",
      "196 gg (275)\n",
      "197 gg (276)\n",
      "198 gg (277)\n",
      "199 gg (278)\n",
      "200 gg (279)\n",
      "201 gg (28)\n",
      "202 gg (280)\n",
      "203 gg (281)\n",
      "204 gg (282)\n",
      "205 gg (283)\n",
      "206 gg (284)\n",
      "207 gg (285)\n",
      "208 gg (286)\n",
      "209 gg (287)\n",
      "210 gg (288)\n",
      "211 gg (289)\n",
      "212 gg (29)\n",
      "213 gg (290)\n",
      "214 gg (291)\n",
      "215 gg (292)\n",
      "216 gg (293)\n",
      "217 gg (294)\n",
      "218 gg (295)\n",
      "219 gg (296)\n",
      "220 gg (297)\n",
      "221 gg (298)\n",
      "222 gg (299)\n",
      "223 gg (3)\n",
      "224 gg (30)\n",
      "225 gg (300)\n",
      "226 gg (301)\n",
      "227 gg (302)\n",
      "228 gg (303)\n",
      "229 gg (304)\n",
      "230 gg (305)\n",
      "231 gg (306)\n",
      "232 gg (307)\n",
      "233 gg (308)\n",
      "234 gg (309)\n",
      "235 gg (31)\n",
      "236 gg (310)\n",
      "237 gg (311)\n",
      "238 gg (312)\n",
      "239 gg (313)\n",
      "240 gg (314)\n",
      "241 gg (315)\n",
      "242 gg (316)\n",
      "243 gg (317)\n",
      "244 gg (318)\n",
      "245 gg (319)\n",
      "246 gg (32)\n",
      "247 gg (320)\n",
      "248 gg (321)\n",
      "249 gg (322)\n",
      "250 gg (323)\n",
      "251 gg (324)\n",
      "252 gg (325)\n",
      "253 gg (326)\n",
      "254 gg (327)\n",
      "255 gg (328)\n",
      "256 gg (329)\n",
      "257 gg (33)\n",
      "258 gg (330)\n",
      "259 gg (331)\n",
      "260 gg (332)\n",
      "261 gg (333)\n",
      "262 gg (334)\n",
      "263 gg (335)\n",
      "264 gg (336)\n",
      "265 gg (337)\n",
      "266 gg (338)\n",
      "267 gg (339)\n",
      "268 gg (34)\n",
      "269 gg (340)\n",
      "270 gg (341)\n",
      "271 gg (342)\n",
      "272 gg (343)\n",
      "273 gg (344)\n",
      "274 gg (345)\n",
      "275 gg (346)\n",
      "276 gg (347)\n",
      "277 gg (348)\n",
      "278 gg (349)\n",
      "279 gg (35)\n",
      "280 gg (350)\n",
      "281 gg (351)\n",
      "282 gg (352)\n",
      "283 gg (353)\n",
      "284 gg (354)\n",
      "285 gg (355)\n",
      "286 gg (356)\n",
      "287 gg (357)\n",
      "288 gg (358)\n",
      "289 gg (359)\n",
      "290 gg (36)\n",
      "291 gg (360)\n",
      "292 gg (361)\n",
      "293 gg (362)\n",
      "294 gg (363)\n",
      "295 gg (364)\n",
      "296 gg (365)\n",
      "297 gg (366)\n",
      "298 gg (367)\n",
      "299 gg (368)\n",
      "300 gg (369)\n",
      "301 gg (37)\n",
      "302 gg (370)\n",
      "303 gg (371)\n",
      "304 gg (372)\n",
      "305 gg (373)\n",
      "306 gg (374)\n",
      "307 gg (375)\n",
      "308 gg (376)\n",
      "309 gg (377)\n",
      "310 gg (378)\n",
      "311 gg (379)\n",
      "312 gg (38)\n",
      "313 gg (380)\n",
      "314 gg (381)\n",
      "315 gg (382)\n",
      "316 gg (383)\n",
      "317 gg (384)\n",
      "318 gg (385)\n",
      "319 gg (386)\n",
      "320 gg (387)\n",
      "321 gg (388)\n",
      "322 gg (389)\n",
      "323 gg (39)\n",
      "324 gg (390)\n",
      "325 gg (391)\n",
      "326 gg (392)\n",
      "327 gg (393)\n",
      "328 gg (394)\n",
      "329 gg (395)\n",
      "330 gg (396)\n",
      "331 gg (397)\n",
      "332 gg (398)\n",
      "333 gg (399)\n",
      "334 gg (4)\n",
      "335 gg (40)\n",
      "336 gg (400)\n",
      "337 gg (401)\n",
      "338 gg (402)\n",
      "339 gg (403)\n",
      "340 gg (404)\n",
      "341 gg (405)\n",
      "342 gg (406)\n",
      "343 gg (407)\n",
      "344 gg (408)\n",
      "345 gg (409)\n",
      "346 gg (41)\n",
      "347 gg (410)\n",
      "348 gg (411)\n",
      "349 gg (412)\n",
      "350 gg (413)\n",
      "351 gg (414)\n",
      "352 gg (415)\n",
      "353 gg (416)\n",
      "354 gg (417)\n",
      "355 gg (418)\n",
      "356 gg (419)\n",
      "357 gg (42)\n",
      "358 gg (420)\n",
      "359 gg (421)\n",
      "360 gg (422)\n",
      "361 gg (423)\n",
      "362 gg (424)\n",
      "363 gg (425)\n",
      "364 gg (426)\n",
      "365 gg (427)\n",
      "366 gg (428)\n",
      "367 gg (429)\n",
      "368 gg (43)\n",
      "369 gg (430)\n",
      "370 gg (431)\n",
      "371 gg (432)\n",
      "372 gg (433)\n",
      "373 gg (434)\n",
      "374 gg (435)\n",
      "375 gg (436)\n",
      "376 gg (437)\n",
      "377 gg (438)\n",
      "378 gg (439)\n",
      "379 gg (44)\n",
      "380 gg (440)\n",
      "381 gg (441)\n",
      "382 gg (442)\n",
      "383 gg (443)\n",
      "384 gg (444)\n",
      "385 gg (445)\n",
      "386 gg (446)\n",
      "387 gg (447)\n",
      "388 gg (448)\n",
      "389 gg (449)\n",
      "390 gg (45)\n",
      "391 gg (450)\n",
      "392 gg (451)\n",
      "393 gg (452)\n",
      "394 gg (453)\n",
      "395 gg (454)\n",
      "396 gg (455)\n",
      "397 gg (456)\n",
      "398 gg (457)\n",
      "399 gg (458)\n",
      "400 gg (459)\n",
      "401 gg (46)\n",
      "402 gg (460)\n",
      "403 gg (461)\n",
      "404 gg (462)\n",
      "405 gg (463)\n",
      "406 gg (464)\n",
      "407 gg (465)\n",
      "408 gg (466)\n",
      "409 gg (467)\n",
      "410 gg (468)\n",
      "411 gg (469)\n",
      "412 gg (47)\n",
      "413 gg (470)\n",
      "414 gg (471)\n",
      "415 gg (472)\n",
      "416 gg (473)\n",
      "417 gg (474)\n",
      "418 gg (475)\n",
      "419 gg (476)\n",
      "420 gg (477)\n",
      "421 gg (478)\n",
      "422 gg (479)\n",
      "423 gg (48)\n",
      "424 gg (480)\n",
      "425 gg (481)\n",
      "426 gg (482)\n",
      "427 gg (483)\n",
      "428 gg (484)\n",
      "429 gg (485)\n",
      "430 gg (486)\n",
      "431 gg (487)\n",
      "432 gg (488)\n",
      "433 gg (489)\n",
      "434 gg (49)\n",
      "435 gg (490)\n",
      "436 gg (491)\n",
      "437 gg (492)\n",
      "438 gg (493)\n",
      "439 gg (494)\n",
      "440 gg (495)\n",
      "441 gg (496)\n",
      "442 gg (497)\n",
      "443 gg (498)\n",
      "444 gg (499)\n",
      "445 gg (5)\n",
      "446 gg (50)\n",
      "447 gg (500)\n",
      "448 gg (501)\n",
      "449 gg (502)\n",
      "450 gg (503)\n",
      "451 gg (504)\n",
      "452 gg (505)\n",
      "453 gg (506)\n",
      "454 gg (507)\n",
      "455 gg (508)\n",
      "456 gg (509)\n",
      "457 gg (51)\n",
      "458 gg (510)\n",
      "459 gg (511)\n",
      "460 gg (512)\n",
      "461 gg (513)\n",
      "462 gg (514)\n",
      "463 gg (515)\n",
      "464 gg (516)\n",
      "465 gg (517)\n",
      "466 gg (518)\n",
      "467 gg (519)\n",
      "468 gg (52)\n",
      "469 gg (520)\n",
      "470 gg (521)\n",
      "471 gg (522)\n",
      "472 gg (523)\n",
      "473 gg (524)\n",
      "474 gg (525)\n",
      "475 gg (526)\n",
      "476 gg (527)\n",
      "477 gg (528)\n",
      "478 gg (529)\n",
      "479 gg (53)\n",
      "480 gg (530)\n",
      "481 gg (531)\n",
      "482 gg (532)\n",
      "483 gg (533)\n",
      "484 gg (534)\n",
      "485 gg (535)\n",
      "486 gg (536)\n",
      "487 gg (537)\n",
      "488 gg (538)\n",
      "489 gg (539)\n",
      "490 gg (54)\n",
      "491 gg (540)\n",
      "492 gg (541)\n",
      "493 gg (542)\n",
      "494 gg (543)\n",
      "495 gg (544)\n",
      "496 gg (545)\n",
      "497 gg (546)\n",
      "498 gg (547)\n",
      "499 gg (548)\n",
      "500 gg (549)\n",
      "501 gg (55)\n",
      "502 gg (550)\n",
      "503 gg (551)\n",
      "504 gg (552)\n",
      "505 gg (553)\n",
      "506 gg (554)\n",
      "507 gg (555)\n",
      "508 gg (556)\n",
      "509 gg (557)\n",
      "510 gg (558)\n",
      "511 gg (559)\n",
      "512 gg (56)\n",
      "513 gg (560)\n",
      "514 gg (561)\n",
      "515 gg (562)\n",
      "516 gg (563)\n",
      "517 gg (564)\n",
      "518 gg (565)\n",
      "519 gg (566)\n",
      "520 gg (567)\n",
      "521 gg (568)\n",
      "522 gg (569)\n",
      "523 gg (57)\n",
      "524 gg (570)\n",
      "525 gg (571)\n",
      "526 gg (572)\n",
      "527 gg (573)\n",
      "528 gg (574)\n",
      "529 gg (575)\n",
      "530 gg (576)\n",
      "531 gg (577)\n",
      "532 gg (578)\n",
      "533 gg (579)\n",
      "534 gg (58)\n",
      "535 gg (580)\n",
      "536 gg (581)\n",
      "537 gg (582)\n",
      "538 gg (583)\n",
      "539 gg (584)\n",
      "540 gg (585)\n",
      "541 gg (586)\n",
      "542 gg (587)\n",
      "543 gg (588)\n",
      "544 gg (589)\n",
      "545 gg (59)\n",
      "546 gg (590)\n",
      "547 gg (591)\n",
      "548 gg (592)\n",
      "549 gg (593)\n",
      "550 gg (594)\n",
      "551 gg (595)\n",
      "552 gg (596)\n",
      "553 gg (597)\n",
      "554 gg (598)\n",
      "555 gg (599)\n",
      "556 gg (6)\n",
      "557 gg (60)\n",
      "558 gg (600)\n",
      "559 gg (601)\n",
      "560 gg (602)\n",
      "561 gg (603)\n",
      "562 gg (604)\n",
      "563 gg (605)\n",
      "564 gg (606)\n",
      "565 gg (607)\n",
      "566 gg (608)\n",
      "567 gg (609)\n",
      "568 gg (61)\n",
      "569 gg (610)\n",
      "570 gg (611)\n",
      "571 gg (612)\n",
      "572 gg (613)\n",
      "573 gg (614)\n",
      "574 gg (615)\n",
      "575 gg (616)\n",
      "576 gg (617)\n",
      "577 gg (618)\n",
      "578 gg (619)\n",
      "579 gg (62)\n",
      "580 gg (620)\n",
      "581 gg (621)\n",
      "582 gg (622)\n",
      "583 gg (623)\n",
      "584 gg (624)\n",
      "585 gg (625)\n",
      "586 gg (626)\n",
      "587 gg (627)\n",
      "588 gg (628)\n",
      "589 gg (629)\n",
      "590 gg (63)\n",
      "591 gg (630)\n",
      "592 gg (631)\n",
      "593 gg (632)\n",
      "594 gg (633)\n",
      "595 gg (634)\n",
      "596 gg (635)\n",
      "597 gg (636)\n",
      "598 gg (637)\n",
      "599 gg (638)\n",
      "600 gg (639)\n",
      "601 gg (64)\n",
      "602 gg (640)\n",
      "603 gg (641)\n",
      "604 gg (642)\n",
      "605 gg (643)\n",
      "606 gg (644)\n",
      "607 gg (645)\n",
      "608 gg (646)\n",
      "609 gg (647)\n",
      "610 gg (648)\n",
      "611 gg (649)\n",
      "612 gg (65)\n",
      "613 gg (650)\n",
      "614 gg (651)\n",
      "615 gg (652)\n",
      "616 gg (653)\n",
      "617 gg (654)\n",
      "618 gg (655)\n",
      "619 gg (656)\n",
      "620 gg (657)\n",
      "621 gg (658)\n",
      "622 gg (659)\n",
      "623 gg (66)\n",
      "624 gg (660)\n",
      "625 gg (661)\n",
      "626 gg (662)\n",
      "627 gg (663)\n",
      "628 gg (664)\n",
      "629 gg (665)\n",
      "630 gg (666)\n",
      "631 gg (667)\n",
      "632 gg (668)\n",
      "633 gg (669)\n",
      "634 gg (67)\n",
      "635 gg (670)\n",
      "636 gg (671)\n",
      "637 gg (672)\n",
      "638 gg (673)\n",
      "639 gg (674)\n",
      "640 gg (675)\n",
      "641 gg (676)\n",
      "642 gg (677)\n",
      "643 gg (678)\n",
      "644 gg (679)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "645 gg (68)\n",
      "646 gg (680)\n",
      "647 gg (681)\n",
      "648 gg (682)\n",
      "649 gg (683)\n",
      "650 gg (684)\n",
      "651 gg (685)\n",
      "652 gg (686)\n",
      "653 gg (687)\n",
      "654 gg (688)\n",
      "655 gg (689)\n",
      "656 gg (69)\n",
      "657 gg (690)\n",
      "658 gg (691)\n",
      "659 gg (692)\n",
      "660 gg (693)\n",
      "661 gg (694)\n",
      "662 gg (695)\n",
      "663 gg (696)\n",
      "664 gg (697)\n",
      "665 gg (698)\n",
      "666 gg (699)\n",
      "667 gg (7)\n",
      "668 gg (70)\n",
      "669 gg (700)\n",
      "670 gg (701)\n",
      "671 gg (702)\n",
      "672 gg (703)\n",
      "673 gg (704)\n",
      "674 gg (705)\n",
      "675 gg (706)\n",
      "676 gg (707)\n",
      "677 gg (708)\n",
      "678 gg (709)\n",
      "679 gg (71)\n",
      "680 gg (710)\n",
      "681 gg (711)\n",
      "682 gg (712)\n",
      "683 gg (713)\n",
      "684 gg (714)\n",
      "685 gg (715)\n",
      "686 gg (716)\n",
      "687 gg (717)\n",
      "688 gg (718)\n",
      "689 gg (719)\n",
      "690 gg (72)\n",
      "691 gg (720)\n",
      "692 gg (721)\n",
      "693 gg (722)\n",
      "694 gg (723)\n",
      "695 gg (724)\n",
      "696 gg (725)\n",
      "697 gg (726)\n",
      "698 gg (727)\n",
      "699 gg (728)\n",
      "700 gg (729)\n",
      "701 gg (73)\n",
      "702 gg (730)\n",
      "703 gg (731)\n",
      "704 gg (732)\n",
      "705 gg (733)\n",
      "706 gg (734)\n",
      "707 gg (735)\n",
      "708 gg (736)\n",
      "709 gg (737)\n",
      "710 gg (738)\n",
      "711 gg (739)\n",
      "712 gg (74)\n",
      "713 gg (740)\n",
      "714 gg (741)\n",
      "715 gg (742)\n",
      "716 gg (743)\n",
      "717 gg (744)\n",
      "718 gg (745)\n",
      "719 gg (746)\n",
      "720 gg (747)\n",
      "721 gg (748)\n",
      "722 gg (749)\n",
      "723 gg (75)\n",
      "724 gg (750)\n",
      "725 gg (751)\n",
      "726 gg (752)\n",
      "727 gg (753)\n",
      "728 gg (754)\n",
      "729 gg (755)\n",
      "730 gg (756)\n",
      "731 gg (757)\n",
      "732 gg (758)\n",
      "733 gg (759)\n",
      "734 gg (76)\n",
      "735 gg (760)\n",
      "736 gg (761)\n",
      "737 gg (762)\n",
      "738 gg (763)\n",
      "739 gg (764)\n",
      "740 gg (765)\n",
      "741 gg (766)\n",
      "742 gg (767)\n",
      "743 gg (768)\n",
      "744 gg (769)\n",
      "745 gg (77)\n",
      "746 gg (770)\n",
      "747 gg (771)\n",
      "748 gg (772)\n",
      "749 gg (773)\n",
      "750 gg (774)\n",
      "751 gg (775)\n",
      "752 gg (776)\n",
      "753 gg (777)\n",
      "754 gg (778)\n",
      "755 gg (779)\n",
      "756 gg (78)\n",
      "757 gg (780)\n",
      "758 gg (781)\n",
      "759 gg (782)\n",
      "760 gg (783)\n",
      "761 gg (784)\n",
      "762 gg (785)\n",
      "763 gg (786)\n",
      "764 gg (787)\n",
      "765 gg (788)\n",
      "766 gg (789)\n",
      "767 gg (79)\n",
      "768 gg (790)\n",
      "769 gg (791)\n",
      "770 gg (792)\n",
      "771 gg (793)\n",
      "772 gg (794)\n",
      "773 gg (795)\n",
      "774 gg (796)\n",
      "775 gg (797)\n",
      "776 gg (798)\n",
      "777 gg (799)\n",
      "778 gg (8)\n",
      "779 gg (80)\n",
      "780 gg (800)\n",
      "781 gg (801)\n",
      "782 gg (802)\n",
      "783 gg (803)\n",
      "784 gg (804)\n",
      "785 gg (805)\n",
      "786 gg (806)\n",
      "787 gg (807)\n",
      "788 gg (808)\n",
      "789 gg (809)\n",
      "790 gg (81)\n",
      "791 gg (810)\n",
      "792 gg (811)\n",
      "793 gg (812)\n",
      "794 gg (813)\n",
      "795 gg (814)\n",
      "796 gg (815)\n",
      "797 gg (816)\n",
      "798 gg (817)\n",
      "799 gg (818)\n",
      "800 gg (819)\n",
      "801 gg (82)\n",
      "802 gg (820)\n",
      "803 gg (821)\n",
      "804 gg (822)\n",
      "805 gg (823)\n",
      "806 gg (824)\n",
      "807 gg (825)\n",
      "808 gg (826)\n",
      "809 gg (83)\n",
      "810 gg (84)\n",
      "811 gg (85)\n",
      "812 gg (86)\n",
      "813 gg (87)\n",
      "814 gg (88)\n",
      "815 gg (89)\n",
      "816 gg (9)\n",
      "817 gg (90)\n",
      "818 gg (91)\n",
      "819 gg (92)\n",
      "820 gg (93)\n",
      "821 gg (94)\n",
      "822 gg (95)\n",
      "823 gg (96)\n",
      "824 gg (97)\n",
      "825 gg (98)\n",
      "826 gg (99)\n",
      "827 image(1)\n",
      "828 image(10)\n",
      "829 image(11)\n",
      "830 image(12)\n",
      "831 image(13)\n",
      "832 image(14)\n",
      "833 image(15)\n",
      "834 image(16)\n",
      "835 image(17)\n",
      "836 image(18)\n",
      "837 image(19)\n",
      "838 image(2)\n",
      "839 image(20)\n",
      "840 image(21)\n",
      "841 image(22)\n",
      "842 image(23)\n",
      "843 image(24)\n",
      "844 image(25)\n",
      "845 image(26)\n",
      "846 image(27)\n",
      "847 image(28)\n",
      "848 image(29)\n",
      "849 image(3)\n",
      "850 image(30)\n",
      "851 image(31)\n",
      "852 image(32)\n",
      "853 image(33)\n",
      "854 image(34)\n",
      "855 image(35)\n",
      "856 image(36)\n",
      "857 image(37)\n",
      "858 image(38)\n",
      "859 image(39)\n",
      "860 image(4)\n",
      "861 image(40)\n",
      "862 image(41)\n",
      "863 image(42)\n",
      "864 image(43)\n",
      "865 image(44)\n",
      "866 image(45)\n",
      "867 image(46)\n",
      "868 image(47)\n",
      "869 image(48)\n",
      "870 image(49)\n",
      "871 image(5)\n",
      "872 image(51)\n",
      "873 image(52)\n",
      "874 image(53)\n",
      "875 image(54)\n",
      "876 image(56)\n",
      "877 image(57)\n",
      "878 image(58)\n",
      "879 image(59)\n",
      "880 image(6)\n",
      "881 image(60)\n",
      "882 image(61)\n",
      "883 image(62)\n",
      "884 image(63)\n",
      "885 image(64)\n",
      "886 image(65)\n",
      "887 image(66)\n",
      "888 image(67)\n",
      "889 image(68)\n",
      "890 image(69)\n",
      "891 image(7)\n",
      "892 image(70)\n",
      "893 image(71)\n",
      "894 image(72)\n",
      "895 image(73)\n",
      "896 image(74)\n",
      "897 image(75)\n",
      "898 image(76)\n",
      "899 image(8)\n",
      "900 image(9)\n"
     ]
    }
   ],
   "source": [
    "for path in glob.glob(test_img_folder):\n",
    "    idx += 1\n",
    "    base = osp.splitext(osp.basename(path))[0]\n",
    "    print(idx, base)\n",
    "    # read images\n",
    "    img = cv2.imread(path, cv2.IMREAD_COLOR)\n",
    "    img = img * 1.0 / 255\n",
    "    img = torch.from_numpy(np.transpose(img[:, :, [2, 1, 0]], (2, 0, 1))).float()\n",
    "    img_LR = img.unsqueeze(0)\n",
    "    img_LR = img_LR.to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        output = model(img_LR).data.squeeze().float().cpu().clamp_(0, 1).numpy()\n",
    "    output = np.transpose(output[[2, 1, 0], :, :], (1, 2, 0))\n",
    "    output = (output * 255.0).round()\n",
    "    cv2.imwrite('output/gliomatumor/{:s}_rlt.png'.format(base), output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_img_folder = 'archive/pituitary_tumor/*'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model path models/RRDB_ESRGAN_x4.pth. \n",
      "Testing...\n"
     ]
    }
   ],
   "source": [
    "model = arch.RRDBNet(3, 3, 64, 23, gc=32)\n",
    "model.load_state_dict(torch.load(model_path), strict=True)\n",
    "model.eval()\n",
    "model = model.to(device)\n",
    "\n",
    "print('Model path {:s}. \\nTesting...'.format(model_path))\n",
    "\n",
    "idx = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 image(1)\n",
      "2 image(10)\n",
      "3 image(11)\n",
      "4 image(13)\n",
      "5 image(15)\n",
      "6 image(18)\n",
      "7 image(19)\n",
      "8 image(2)\n",
      "9 image(20)\n",
      "10 image(21)\n",
      "11 image(22)\n",
      "12 image(23)\n",
      "13 image(27)\n",
      "14 image(28)\n",
      "15 image(3)\n",
      "16 image(30)\n",
      "17 image(31)\n",
      "18 image(34)\n",
      "19 image(35)\n",
      "20 image(36)\n",
      "21 image(37)\n",
      "22 image(38)\n",
      "23 image(41)\n",
      "24 image(42)\n",
      "25 image(43)\n",
      "26 image(44)\n",
      "27 image(45)\n",
      "28 image(46)\n",
      "29 image(47)\n",
      "30 image(48)\n",
      "31 image(49)\n",
      "32 image(5)\n",
      "33 image(51)\n",
      "34 image(52)\n",
      "35 image(53)\n",
      "36 image(54)\n",
      "37 image(55)\n",
      "38 image(56)\n",
      "39 image(57)\n",
      "40 image(6)\n",
      "41 image(60)\n",
      "42 image(61)\n",
      "43 image(63)\n",
      "44 image(64)\n",
      "45 image(65)\n",
      "46 image(66)\n",
      "47 image(67)\n",
      "48 image(68)\n",
      "49 image(69)\n",
      "50 image(7)\n",
      "51 image(70)\n",
      "52 image(73)\n",
      "53 image(76)\n",
      "54 image(77)\n",
      "55 image(78)\n",
      "56 image(79)\n",
      "57 image(8)\n",
      "58 image(81)\n",
      "59 image(82)\n",
      "60 image(85)\n",
      "61 image(86)\n",
      "62 image(87)\n",
      "63 image(88)\n",
      "64 image(89)\n",
      "65 image(90)\n",
      "66 image(91)\n",
      "67 image(92)\n",
      "68 image(93)\n",
      "69 image(94)\n",
      "70 image(95)\n",
      "71 image(96)\n",
      "72 image(97)\n",
      "73 image(98)\n",
      "74 image\n",
      "75 p (1)\n",
      "76 p (10)\n",
      "77 p (100)\n",
      "78 p (101)\n",
      "79 p (102)\n",
      "80 p (103)\n",
      "81 p (104)\n",
      "82 p (105)\n",
      "83 p (106)\n",
      "84 p (107)\n",
      "85 p (108)\n",
      "86 p (109)\n",
      "87 p (11)\n",
      "88 p (110)\n",
      "89 p (111)\n",
      "90 p (112)\n",
      "91 p (113)\n",
      "92 p (114)\n",
      "93 p (115)\n",
      "94 p (116)\n",
      "95 p (117)\n",
      "96 p (118)\n",
      "97 p (119)\n",
      "98 p (12)\n",
      "99 p (120)\n",
      "100 p (121)\n",
      "101 p (122)\n",
      "102 p (123)\n",
      "103 p (124)\n",
      "104 p (125)\n",
      "105 p (126)\n",
      "106 p (127)\n",
      "107 p (128)\n",
      "108 p (129)\n",
      "109 p (13)\n",
      "110 p (130)\n",
      "111 p (131)\n",
      "112 p (132)\n",
      "113 p (133)\n",
      "114 p (134)\n",
      "115 p (135)\n",
      "116 p (136)\n",
      "117 p (137)\n",
      "118 p (138)\n",
      "119 p (139)\n",
      "120 p (14)\n",
      "121 p (140)\n",
      "122 p (141)\n",
      "123 p (142)\n",
      "124 p (143)\n",
      "125 p (144)\n",
      "126 p (145)\n",
      "127 p (146)\n",
      "128 p (147)\n",
      "129 p (148)\n",
      "130 p (149)\n",
      "131 p (15)\n",
      "132 p (150)\n",
      "133 p (151)\n",
      "134 p (152)\n",
      "135 p (153)\n",
      "136 p (154)\n",
      "137 p (155)\n",
      "138 p (156)\n",
      "139 p (157)\n",
      "140 p (158)\n",
      "141 p (159)\n",
      "142 p (16)\n",
      "143 p (160)\n",
      "144 p (161)\n",
      "145 p (162)\n",
      "146 p (163)\n",
      "147 p (164)\n",
      "148 p (165)\n",
      "149 p (166)\n",
      "150 p (167)\n",
      "151 p (168)\n",
      "152 p (169)\n",
      "153 p (17)\n",
      "154 p (170)\n",
      "155 p (171)\n",
      "156 p (172)\n",
      "157 p (173)\n",
      "158 p (174)\n",
      "159 p (175)\n",
      "160 p (176)\n",
      "161 p (177)\n",
      "162 p (178)\n",
      "163 p (179)\n",
      "164 p (18)\n",
      "165 p (180)\n",
      "166 p (181)\n",
      "167 p (182)\n",
      "168 p (183)\n",
      "169 p (184)\n",
      "170 p (185)\n",
      "171 p (186)\n",
      "172 p (187)\n",
      "173 p (188)\n",
      "174 p (189)\n",
      "175 p (19)\n",
      "176 p (190)\n",
      "177 p (191)\n",
      "178 p (192)\n",
      "179 p (193)\n",
      "180 p (194)\n",
      "181 p (195)\n",
      "182 p (196)\n",
      "183 p (197)\n",
      "184 p (198)\n",
      "185 p (199)\n",
      "186 p (2)\n",
      "187 p (20)\n",
      "188 p (200)\n",
      "189 p (201)\n",
      "190 p (202)\n",
      "191 p (203)\n",
      "192 p (204)\n",
      "193 p (205)\n",
      "194 p (206)\n",
      "195 p (207)\n",
      "196 p (208)\n",
      "197 p (209)\n",
      "198 p (21)\n",
      "199 p (210)\n",
      "200 p (211)\n",
      "201 p (212)\n",
      "202 p (213)\n",
      "203 p (214)\n",
      "204 p (215)\n",
      "205 p (216)\n",
      "206 p (217)\n",
      "207 p (218)\n",
      "208 p (219)\n",
      "209 p (22)\n",
      "210 p (220)\n",
      "211 p (221)\n",
      "212 p (222)\n",
      "213 p (223)\n",
      "214 p (224)\n",
      "215 p (225)\n",
      "216 p (226)\n",
      "217 p (227)\n",
      "218 p (228)\n",
      "219 p (229)\n",
      "220 p (23)\n",
      "221 p (230)\n",
      "222 p (231)\n",
      "223 p (232)\n",
      "224 p (233)\n",
      "225 p (234)\n",
      "226 p (235)\n",
      "227 p (236)\n",
      "228 p (237)\n",
      "229 p (238)\n",
      "230 p (239)\n",
      "231 p (24)\n",
      "232 p (240)\n",
      "233 p (241)\n",
      "234 p (242)\n",
      "235 p (243)\n",
      "236 p (244)\n",
      "237 p (245)\n",
      "238 p (246)\n",
      "239 p (247)\n",
      "240 p (248)\n",
      "241 p (249)\n",
      "242 p (25)\n",
      "243 p (250)\n",
      "244 p (251)\n",
      "245 p (252)\n",
      "246 p (253)\n",
      "247 p (254)\n",
      "248 p (255)\n",
      "249 p (256)\n",
      "250 p (257)\n",
      "251 p (258)\n",
      "252 p (259)\n",
      "253 p (26)\n",
      "254 p (260)\n",
      "255 p (261)\n",
      "256 p (262)\n",
      "257 p (263)\n",
      "258 p (264)\n",
      "259 p (265)\n",
      "260 p (266)\n",
      "261 p (267)\n",
      "262 p (268)\n",
      "263 p (269)\n",
      "264 p (27)\n",
      "265 p (270)\n",
      "266 p (271)\n",
      "267 p (272)\n",
      "268 p (273)\n",
      "269 p (274)\n",
      "270 p (275)\n",
      "271 p (276)\n",
      "272 p (277)\n",
      "273 p (278)\n",
      "274 p (279)\n",
      "275 p (28)\n",
      "276 p (280)\n",
      "277 p (281)\n",
      "278 p (282)\n",
      "279 p (283)\n",
      "280 p (284)\n",
      "281 p (285)\n",
      "282 p (286)\n",
      "283 p (287)\n",
      "284 p (288)\n",
      "285 p (289)\n",
      "286 p (29)\n",
      "287 p (290)\n",
      "288 p (291)\n",
      "289 p (292)\n",
      "290 p (293)\n",
      "291 p (294)\n",
      "292 p (295)\n",
      "293 p (296)\n",
      "294 p (297)\n",
      "295 p (298)\n",
      "296 p (299)\n",
      "297 p (3)\n",
      "298 p (30)\n",
      "299 p (300)\n",
      "300 p (301)\n",
      "301 p (302)\n",
      "302 p (303)\n",
      "303 p (304)\n",
      "304 p (305)\n",
      "305 p (306)\n",
      "306 p (307)\n",
      "307 p (308)\n",
      "308 p (309)\n",
      "309 p (31)\n",
      "310 p (310)\n",
      "311 p (311)\n",
      "312 p (312)\n",
      "313 p (313)\n",
      "314 p (314)\n",
      "315 p (315)\n",
      "316 p (316)\n",
      "317 p (317)\n",
      "318 p (318)\n",
      "319 p (319)\n",
      "320 p (32)\n",
      "321 p (320)\n",
      "322 p (321)\n",
      "323 p (322)\n",
      "324 p (323)\n",
      "325 p (324)\n",
      "326 p (325)\n",
      "327 p (326)\n",
      "328 p (327)\n",
      "329 p (328)\n",
      "330 p (329)\n",
      "331 p (33)\n",
      "332 p (330)\n",
      "333 p (331)\n",
      "334 p (332)\n",
      "335 p (333)\n",
      "336 p (334)\n",
      "337 p (335)\n",
      "338 p (336)\n",
      "339 p (337)\n",
      "340 p (338)\n",
      "341 p (339)\n",
      "342 p (34)\n",
      "343 p (340)\n",
      "344 p (341)\n",
      "345 p (342)\n",
      "346 p (343)\n",
      "347 p (344)\n",
      "348 p (345)\n",
      "349 p (346)\n",
      "350 p (347)\n",
      "351 p (348)\n",
      "352 p (349)\n",
      "353 p (35)\n",
      "354 p (350)\n",
      "355 p (351)\n",
      "356 p (352)\n",
      "357 p (353)\n",
      "358 p (354)\n",
      "359 p (355)\n",
      "360 p (356)\n",
      "361 p (357)\n",
      "362 p (358)\n",
      "363 p (359)\n",
      "364 p (36)\n",
      "365 p (360)\n",
      "366 p (361)\n",
      "367 p (362)\n",
      "368 p (363)\n",
      "369 p (364)\n",
      "370 p (365)\n",
      "371 p (366)\n",
      "372 p (367)\n",
      "373 p (368)\n",
      "374 p (369)\n",
      "375 p (37)\n",
      "376 p (370)\n",
      "377 p (371)\n",
      "378 p (372)\n",
      "379 p (373)\n",
      "380 p (374)\n",
      "381 p (375)\n",
      "382 p (376)\n",
      "383 p (377)\n",
      "384 p (378)\n",
      "385 p (379)\n",
      "386 p (38)\n",
      "387 p (380)\n",
      "388 p (381)\n",
      "389 p (382)\n",
      "390 p (383)\n",
      "391 p (384)\n",
      "392 p (385)\n",
      "393 p (386)\n",
      "394 p (387)\n",
      "395 p (388)\n",
      "396 p (389)\n",
      "397 p (39)\n",
      "398 p (390)\n",
      "399 p (391)\n",
      "400 p (392)\n",
      "401 p (393)\n",
      "402 p (394)\n",
      "403 p (395)\n",
      "404 p (396)\n",
      "405 p (397)\n",
      "406 p (398)\n",
      "407 p (399)\n",
      "408 p (4)\n",
      "409 p (40)\n",
      "410 p (400)\n",
      "411 p (401)\n",
      "412 p (402)\n",
      "413 p (403)\n",
      "414 p (404)\n",
      "415 p (405)\n",
      "416 p (406)\n",
      "417 p (407)\n",
      "418 p (408)\n",
      "419 p (409)\n",
      "420 p (41)\n",
      "421 p (410)\n",
      "422 p (411)\n",
      "423 p (412)\n",
      "424 p (413)\n",
      "425 p (414)\n",
      "426 p (415)\n",
      "427 p (416)\n",
      "428 p (417)\n",
      "429 p (418)\n",
      "430 p (419)\n",
      "431 p (42)\n",
      "432 p (420)\n",
      "433 p (421)\n",
      "434 p (422)\n",
      "435 p (423)\n",
      "436 p (424)\n",
      "437 p (425)\n",
      "438 p (426)\n",
      "439 p (427)\n",
      "440 p (428)\n",
      "441 p (429)\n",
      "442 p (43)\n",
      "443 p (430)\n",
      "444 p (431)\n",
      "445 p (432)\n",
      "446 p (433)\n",
      "447 p (434)\n",
      "448 p (435)\n",
      "449 p (436)\n",
      "450 p (437)\n",
      "451 p (438)\n",
      "452 p (439)\n",
      "453 p (44)\n",
      "454 p (440)\n",
      "455 p (441)\n",
      "456 p (442)\n",
      "457 p (443)\n",
      "458 p (444)\n",
      "459 p (445)\n",
      "460 p (446)\n",
      "461 p (447)\n",
      "462 p (448)\n",
      "463 p (449)\n",
      "464 p (45)\n",
      "465 p (450)\n",
      "466 p (451)\n",
      "467 p (452)\n",
      "468 p (453)\n",
      "469 p (454)\n",
      "470 p (455)\n",
      "471 p (456)\n",
      "472 p (457)\n",
      "473 p (458)\n",
      "474 p (459)\n",
      "475 p (46)\n",
      "476 p (460)\n",
      "477 p (461)\n",
      "478 p (462)\n",
      "479 p (463)\n",
      "480 p (464)\n",
      "481 p (465)\n",
      "482 p (466)\n",
      "483 p (467)\n",
      "484 p (468)\n",
      "485 p (469)\n",
      "486 p (47)\n",
      "487 p (470)\n",
      "488 p (471)\n",
      "489 p (472)\n",
      "490 p (473)\n",
      "491 p (474)\n",
      "492 p (475)\n",
      "493 p (476)\n",
      "494 p (477)\n",
      "495 p (478)\n",
      "496 p (479)\n",
      "497 p (48)\n",
      "498 p (480)\n",
      "499 p (481)\n",
      "500 p (482)\n",
      "501 p (483)\n",
      "502 p (484)\n",
      "503 p (485)\n",
      "504 p (486)\n",
      "505 p (487)\n",
      "506 p (488)\n",
      "507 p (489)\n",
      "508 p (49)\n",
      "509 p (490)\n",
      "510 p (491)\n",
      "511 p (492)\n",
      "512 p (493)\n",
      "513 p (494)\n",
      "514 p (495)\n",
      "515 p (496)\n",
      "516 p (497)\n",
      "517 p (498)\n",
      "518 p (499)\n",
      "519 p (5)\n",
      "520 p (50)\n",
      "521 p (500)\n",
      "522 p (501)\n",
      "523 p (502)\n",
      "524 p (503)\n",
      "525 p (504)\n",
      "526 p (505)\n",
      "527 p (506)\n",
      "528 p (507)\n",
      "529 p (508)\n",
      "530 p (509)\n",
      "531 p (51)\n",
      "532 p (510)\n",
      "533 p (511)\n",
      "534 p (512)\n",
      "535 p (513)\n",
      "536 p (514)\n",
      "537 p (515)\n",
      "538 p (516)\n",
      "539 p (517)\n",
      "540 p (518)\n",
      "541 p (519)\n",
      "542 p (52)\n",
      "543 p (520)\n",
      "544 p (521)\n",
      "545 p (522)\n",
      "546 p (523)\n",
      "547 p (524)\n",
      "548 p (525)\n",
      "549 p (526)\n",
      "550 p (527)\n",
      "551 p (528)\n",
      "552 p (529)\n",
      "553 p (53)\n",
      "554 p (530)\n",
      "555 p (531)\n",
      "556 p (532)\n",
      "557 p (533)\n",
      "558 p (534)\n",
      "559 p (535)\n",
      "560 p (536)\n",
      "561 p (537)\n",
      "562 p (538)\n",
      "563 p (539)\n",
      "564 p (54)\n",
      "565 p (540)\n",
      "566 p (541)\n",
      "567 p (542)\n",
      "568 p (543)\n",
      "569 p (544)\n",
      "570 p (545)\n",
      "571 p (546)\n",
      "572 p (547)\n",
      "573 p (548)\n",
      "574 p (549)\n",
      "575 p (55)\n",
      "576 p (550)\n",
      "577 p (551)\n",
      "578 p (552)\n",
      "579 p (553)\n",
      "580 p (554)\n",
      "581 p (555)\n",
      "582 p (556)\n",
      "583 p (557)\n",
      "584 p (558)\n",
      "585 p (559)\n",
      "586 p (56)\n",
      "587 p (560)\n",
      "588 p (561)\n",
      "589 p (562)\n",
      "590 p (563)\n",
      "591 p (564)\n",
      "592 p (565)\n",
      "593 p (566)\n",
      "594 p (567)\n",
      "595 p (568)\n",
      "596 p (569)\n",
      "597 p (57)\n",
      "598 p (570)\n",
      "599 p (571)\n",
      "600 p (572)\n",
      "601 p (573)\n",
      "602 p (574)\n",
      "603 p (575)\n",
      "604 p (576)\n",
      "605 p (577)\n",
      "606 p (578)\n",
      "607 p (579)\n",
      "608 p (58)\n",
      "609 p (580)\n",
      "610 p (581)\n",
      "611 p (582)\n",
      "612 p (583)\n",
      "613 p (584)\n",
      "614 p (585)\n",
      "615 p (586)\n",
      "616 p (587)\n",
      "617 p (588)\n",
      "618 p (589)\n",
      "619 p (59)\n",
      "620 p (590)\n",
      "621 p (591)\n",
      "622 p (592)\n",
      "623 p (593)\n",
      "624 p (594)\n",
      "625 p (595)\n",
      "626 p (596)\n",
      "627 p (597)\n",
      "628 p (598)\n",
      "629 p (599)\n",
      "630 p (6)\n",
      "631 p (60)\n",
      "632 p (600)\n",
      "633 p (601)\n",
      "634 p (602)\n",
      "635 p (603)\n",
      "636 p (604)\n",
      "637 p (605)\n",
      "638 p (606)\n",
      "639 p (607)\n",
      "640 p (608)\n",
      "641 p (609)\n",
      "642 p (61)\n",
      "643 p (610)\n",
      "644 p (611)\n",
      "645 p (612)\n",
      "646 p (613)\n",
      "647 p (614)\n",
      "648 p (615)\n",
      "649 p (616)\n",
      "650 p (617)\n",
      "651 p (618)\n",
      "652 p (619)\n",
      "653 p (62)\n",
      "654 p (620)\n",
      "655 p (621)\n",
      "656 p (622)\n",
      "657 p (623)\n",
      "658 p (624)\n",
      "659 p (625)\n",
      "660 p (626)\n",
      "661 p (627)\n",
      "662 p (628)\n",
      "663 p (629)\n",
      "664 p (63)\n",
      "665 p (630)\n",
      "666 p (631)\n",
      "667 p (632)\n",
      "668 p (633)\n",
      "669 p (634)\n",
      "670 p (635)\n",
      "671 p (636)\n",
      "672 p (637)\n",
      "673 p (638)\n",
      "674 p (639)\n",
      "675 p (64)\n",
      "676 p (640)\n",
      "677 p (641)\n",
      "678 p (642)\n",
      "679 p (643)\n",
      "680 p (644)\n",
      "681 p (645)\n",
      "682 p (646)\n",
      "683 p (647)\n",
      "684 p (648)\n",
      "685 p (649)\n",
      "686 p (65)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "687 p (650)\n",
      "688 p (651)\n",
      "689 p (652)\n",
      "690 p (653)\n",
      "691 p (654)\n",
      "692 p (655)\n",
      "693 p (656)\n",
      "694 p (657)\n",
      "695 p (658)\n",
      "696 p (659)\n",
      "697 p (66)\n",
      "698 p (660)\n",
      "699 p (661)\n",
      "700 p (662)\n",
      "701 p (663)\n",
      "702 p (664)\n",
      "703 p (665)\n",
      "704 p (666)\n",
      "705 p (667)\n",
      "706 p (668)\n",
      "707 p (669)\n",
      "708 p (67)\n",
      "709 p (670)\n",
      "710 p (671)\n",
      "711 p (672)\n",
      "712 p (673)\n",
      "713 p (674)\n",
      "714 p (675)\n",
      "715 p (676)\n",
      "716 p (677)\n",
      "717 p (678)\n",
      "718 p (679)\n",
      "719 p (68)\n",
      "720 p (680)\n",
      "721 p (681)\n",
      "722 p (682)\n",
      "723 p (683)\n",
      "724 p (684)\n",
      "725 p (685)\n",
      "726 p (686)\n",
      "727 p (687)\n",
      "728 p (688)\n",
      "729 p (689)\n",
      "730 p (69)\n",
      "731 p (690)\n",
      "732 p (691)\n",
      "733 p (692)\n",
      "734 p (693)\n",
      "735 p (694)\n",
      "736 p (695)\n",
      "737 p (696)\n",
      "738 p (697)\n",
      "739 p (698)\n",
      "740 p (699)\n",
      "741 p (7)\n",
      "742 p (70)\n",
      "743 p (700)\n",
      "744 p (701)\n",
      "745 p (702)\n",
      "746 p (703)\n",
      "747 p (704)\n",
      "748 p (705)\n",
      "749 p (706)\n",
      "750 p (707)\n",
      "751 p (708)\n",
      "752 p (709)\n",
      "753 p (71)\n",
      "754 p (710)\n",
      "755 p (711)\n",
      "756 p (712)\n",
      "757 p (713)\n",
      "758 p (714)\n",
      "759 p (715)\n",
      "760 p (716)\n",
      "761 p (717)\n",
      "762 p (718)\n",
      "763 p (719)\n",
      "764 p (72)\n",
      "765 p (720)\n",
      "766 p (721)\n",
      "767 p (722)\n",
      "768 p (723)\n",
      "769 p (724)\n",
      "770 p (725)\n",
      "771 p (726)\n",
      "772 p (727)\n",
      "773 p (728)\n",
      "774 p (729)\n",
      "775 p (73)\n",
      "776 p (730)\n",
      "777 p (731)\n",
      "778 p (732)\n",
      "779 p (733)\n",
      "780 p (734)\n",
      "781 p (735)\n",
      "782 p (736)\n",
      "783 p (737)\n",
      "784 p (738)\n",
      "785 p (739)\n",
      "786 p (74)\n",
      "787 p (740)\n",
      "788 p (741)\n",
      "789 p (742)\n",
      "790 p (743)\n",
      "791 p (744)\n",
      "792 p (745)\n",
      "793 p (746)\n",
      "794 p (747)\n",
      "795 p (748)\n",
      "796 p (749)\n",
      "797 p (75)\n",
      "798 p (750)\n",
      "799 p (751)\n",
      "800 p (752)\n",
      "801 p (753)\n",
      "802 p (754)\n",
      "803 p (755)\n",
      "804 p (756)\n",
      "805 p (757)\n",
      "806 p (758)\n",
      "807 p (759)\n",
      "808 p (76)\n",
      "809 p (760)\n",
      "810 p (761)\n",
      "811 p (762)\n",
      "812 p (763)\n",
      "813 p (764)\n",
      "814 p (765)\n",
      "815 p (766)\n",
      "816 p (767)\n",
      "817 p (768)\n",
      "818 p (769)\n",
      "819 p (77)\n",
      "820 p (770)\n",
      "821 p (771)\n",
      "822 p (772)\n",
      "823 p (773)\n",
      "824 p (774)\n",
      "825 p (775)\n",
      "826 p (776)\n",
      "827 p (777)\n",
      "828 p (778)\n",
      "829 p (779)\n",
      "830 p (78)\n",
      "831 p (780)\n",
      "832 p (781)\n",
      "833 p (782)\n",
      "834 p (783)\n",
      "835 p (784)\n",
      "836 p (785)\n",
      "837 p (786)\n",
      "838 p (787)\n",
      "839 p (788)\n",
      "840 p (789)\n",
      "841 p (79)\n",
      "842 p (790)\n",
      "843 p (791)\n",
      "844 p (792)\n",
      "845 p (793)\n",
      "846 p (794)\n",
      "847 p (795)\n",
      "848 p (796)\n",
      "849 p (797)\n",
      "850 p (798)\n",
      "851 p (799)\n",
      "852 p (8)\n",
      "853 p (80)\n",
      "854 p (800)\n",
      "855 p (801)\n",
      "856 p (802)\n",
      "857 p (803)\n",
      "858 p (804)\n",
      "859 p (805)\n",
      "860 p (806)\n",
      "861 p (807)\n",
      "862 p (808)\n",
      "863 p (809)\n",
      "864 p (81)\n",
      "865 p (810)\n",
      "866 p (811)\n",
      "867 p (812)\n",
      "868 p (813)\n",
      "869 p (814)\n",
      "870 p (815)\n",
      "871 p (816)\n",
      "872 p (817)\n",
      "873 p (818)\n",
      "874 p (819)\n",
      "875 p (82)\n",
      "876 p (820)\n",
      "877 p (821)\n",
      "878 p (822)\n",
      "879 p (823)\n",
      "880 p (824)\n",
      "881 p (825)\n",
      "882 p (826)\n",
      "883 p (83)\n",
      "884 p (84)\n",
      "885 p (85)\n",
      "886 p (86)\n",
      "887 p (87)\n",
      "888 p (88)\n",
      "889 p (89)\n",
      "890 p (9)\n",
      "891 p (90)\n",
      "892 p (91)\n",
      "893 p (92)\n",
      "894 p (93)\n",
      "895 p (94)\n",
      "896 p (95)\n",
      "897 p (96)\n",
      "898 p (97)\n",
      "899 p (98)\n",
      "900 p (99)\n"
     ]
    }
   ],
   "source": [
    "for path in glob.glob(test_img_folder):\n",
    "    idx += 1\n",
    "    base = osp.splitext(osp.basename(path))[0]\n",
    "    print(idx, base)\n",
    "    # read images\n",
    "    img = cv2.imread(path, cv2.IMREAD_COLOR)\n",
    "    img = img * 1.0 / 255\n",
    "    img = torch.from_numpy(np.transpose(img[:, :, [2, 1, 0]], (2, 0, 1))).float()\n",
    "    img_LR = img.unsqueeze(0)\n",
    "    img_LR = img_LR.to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        output = model(img_LR).data.squeeze().float().cpu().clamp_(0, 1).numpy()\n",
    "    output = np.transpose(output[[2, 1, 0], :, :], (1, 2, 0))\n",
    "    output = (output * 255.0).round()\n",
    "    cv2.imwrite('output/pituitarytumor/{:s}_rlt.png'.format(base), output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import random\n",
    "import os\n",
    "import keras\n",
    "import re\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from keras.preprocessing import image\n",
    "from keras.preprocessing.image import ImageDataGenerator, DataFrameIterator\n",
    "from keras.metrics import Precision, Recall\n",
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import (\n",
    "    Dense,\n",
    "    Flatten,\n",
    "    BatchNormalization,\n",
    "    Conv2D,\n",
    "    MaxPooling2D,\n",
    "    GlobalAveragePooling2D,\n",
    "    Dropout,\n",
    "    Input,\n",
    "    Activation,\n",
    "    concatenate,\n",
    ")\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1440 images belonging to 2 classes.\n",
      "Found 360 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "image_generator = tf.keras.preprocessing.image.ImageDataGenerator(validation_split=0.2)\n",
    "train_data_gen = image_generator.flow_from_directory(directory='output',target_size=(128,128),\n",
    "                                                     subset='training')\n",
    "val_data_gen = image_generator.flow_from_directory(directory='output',target_size=(128,128),\n",
    "                                                   subset='validation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_SIZE = [128,128]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VGG19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.vgg19 import VGG19\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.applications.vgg19 import preprocess_input\n",
    "from tensorflow.keras.models import Model\n",
    "vgg19=VGG19(input_shape = IMAGE_SIZE + [3], weights='imagenet', include_top=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 128, 128, 3)]     0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 128, 128, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 128, 128, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 64, 64, 64)        0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 64, 64, 128)       73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 64, 64, 128)       147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 32, 32, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 32, 32, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 32, 32, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 32, 32, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv4 (Conv2D)        (None, 32, 32, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 16, 16, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 16, 16, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 16, 16, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 16, 16, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv4 (Conv2D)        (None, 16, 16, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 8, 8, 512)         0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 8, 8, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 8, 8, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 8, 8, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv4 (Conv2D)        (None, 8, 8, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 4, 4, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 8192)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 2)                 16386     \n",
      "=================================================================\n",
      "Total params: 20,040,770\n",
      "Trainable params: 20,040,770\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "x11= Flatten()(vgg19.output)\n",
    "prediction11 = Dense(2, activation='softmax')(x11)\n",
    "model11 = Model(inputs = vgg19.inputs, outputs = prediction11)\n",
    "model11.summary()\n",
    "model11.compile(loss = 'categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "45/45 [==============================] - 971s 22s/step - loss: 21.2184 - accuracy: 0.5889 - val_loss: 0.5556 - val_accuracy: 0.7111\n",
      "Epoch 2/200\n",
      "45/45 [==============================] - 1053s 23s/step - loss: 0.4699 - accuracy: 0.7937 - val_loss: 0.6687 - val_accuracy: 0.6556\n",
      "Epoch 3/200\n",
      "45/45 [==============================] - 1044s 23s/step - loss: 0.3426 - accuracy: 0.8833 - val_loss: 0.6849 - val_accuracy: 0.7056\n",
      "Epoch 4/200\n",
      "45/45 [==============================] - 1078s 24s/step - loss: 0.3337 - accuracy: 0.8750 - val_loss: 0.6852 - val_accuracy: 0.6861\n",
      "\n",
      "Epoch 00004: ReduceLROnPlateau reducing learning rate to 0.0003000000142492354.\n",
      "Epoch 5/200\n",
      "45/45 [==============================] - 1045s 23s/step - loss: 0.2695 - accuracy: 0.9056 - val_loss: 0.4993 - val_accuracy: 0.8250\n",
      "Epoch 6/200\n",
      "45/45 [==============================] - 1029s 23s/step - loss: 0.2243 - accuracy: 0.9215 - val_loss: 0.5425 - val_accuracy: 0.7611\n",
      "Epoch 7/200\n",
      "45/45 [==============================] - 1032s 23s/step - loss: 0.1967 - accuracy: 0.9271 - val_loss: 0.5415 - val_accuracy: 0.7750\n",
      "Epoch 8/200\n",
      "45/45 [==============================] - 1067s 24s/step - loss: 0.1744 - accuracy: 0.9361 - val_loss: 0.5394 - val_accuracy: 0.8194\n",
      "\n",
      "Epoch 00008: ReduceLROnPlateau reducing learning rate to 9.000000427477062e-05.\n",
      "Epoch 9/200\n",
      "45/45 [==============================] - 1066s 24s/step - loss: 0.1349 - accuracy: 0.9514 - val_loss: 0.5549 - val_accuracy: 0.8361\n",
      "Epoch 10/200\n",
      "45/45 [==============================] - 914s 20s/step - loss: 0.1198 - accuracy: 0.9618 - val_loss: 0.4985 - val_accuracy: 0.8278\n",
      "Epoch 11/200\n",
      "45/45 [==============================] - 877s 19s/step - loss: 0.1013 - accuracy: 0.9625 - val_loss: 0.5154 - val_accuracy: 0.8306\n",
      "Epoch 12/200\n",
      "45/45 [==============================] - 850s 19s/step - loss: 0.1003 - accuracy: 0.9639 - val_loss: 0.5414 - val_accuracy: 0.8056\n",
      "\n",
      "Epoch 00012: ReduceLROnPlateau reducing learning rate to 2.700000040931627e-05.\n",
      "Epoch 13/200\n",
      "45/45 [==============================] - 878s 20s/step - loss: 0.0805 - accuracy: 0.9715 - val_loss: 0.5539 - val_accuracy: 0.8389\n",
      "Epoch 14/200\n",
      "45/45 [==============================] - 883s 20s/step - loss: 0.0782 - accuracy: 0.9757 - val_loss: 0.5299 - val_accuracy: 0.8389\n",
      "Epoch 15/200\n",
      "45/45 [==============================] - 890s 20s/step - loss: 0.0700 - accuracy: 0.9764 - val_loss: 0.5464 - val_accuracy: 0.8333\n",
      "Epoch 16/200\n",
      "45/45 [==============================] - 872s 19s/step - loss: 0.0674 - accuracy: 0.9806 - val_loss: 0.5565 - val_accuracy: 0.8361\n",
      "\n",
      "Epoch 00016: ReduceLROnPlateau reducing learning rate to 8.100000013655517e-06.\n",
      "Epoch 17/200\n",
      "45/45 [==============================] - 843s 19s/step - loss: 0.0610 - accuracy: 0.9812 - val_loss: 0.5636 - val_accuracy: 0.8472\n",
      "Epoch 18/200\n",
      "45/45 [==============================] - 878s 19s/step - loss: 0.0604 - accuracy: 0.9819 - val_loss: 0.5615 - val_accuracy: 0.8444\n",
      "Epoch 19/200\n",
      "45/45 [==============================] - 891s 20s/step - loss: 0.0590 - accuracy: 0.9819 - val_loss: 0.5601 - val_accuracy: 0.8472\n",
      "Epoch 20/200\n",
      "45/45 [==============================] - 877s 19s/step - loss: 0.0576 - accuracy: 0.9819 - val_loss: 0.5860 - val_accuracy: 0.8417\n",
      "\n",
      "Epoch 00020: ReduceLROnPlateau reducing learning rate to 2.429999949526973e-06.\n",
      "Epoch 21/200\n",
      "45/45 [==============================] - 864s 19s/step - loss: 0.0563 - accuracy: 0.9840 - val_loss: 0.5708 - val_accuracy: 0.8472\n",
      "Epoch 22/200\n",
      "45/45 [==============================] - 861s 19s/step - loss: 0.0556 - accuracy: 0.9847 - val_loss: 0.5734 - val_accuracy: 0.8472\n",
      "Epoch 23/200\n",
      "45/45 [==============================] - 828s 18s/step - loss: 0.0549 - accuracy: 0.9854 - val_loss: 0.5740 - val_accuracy: 0.8472\n",
      "\n",
      "Epoch 00023: ReduceLROnPlateau reducing learning rate to 7.289999985005124e-07.\n",
      "Epoch 24/200\n",
      "45/45 [==============================] - 883s 20s/step - loss: 0.0545 - accuracy: 0.9861 - val_loss: 0.5738 - val_accuracy: 0.8472\n",
      "Epoch 25/200\n",
      "45/45 [==============================] - 881s 20s/step - loss: 0.0544 - accuracy: 0.9861 - val_loss: 0.5742 - val_accuracy: 0.8472\n",
      "Epoch 26/200\n",
      "45/45 [==============================] - 877s 19s/step - loss: 0.0543 - accuracy: 0.9861 - val_loss: 0.5767 - val_accuracy: 0.8472\n",
      "\n",
      "Epoch 00026: ReduceLROnPlateau reducing learning rate to 2.1870000637136398e-07.\n",
      "Epoch 27/200\n",
      "45/45 [==============================] - 836s 19s/step - loss: 0.0541 - accuracy: 0.9861 - val_loss: 0.5765 - val_accuracy: 0.8472\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00027: early stopping\n"
     ]
    }
   ],
   "source": [
    "learning_rate_reduction = ReduceLROnPlateau(\n",
    "    monitor=\"val_accuracy\", patience=3, verbose=1, factor=0.3, min_lr=0.0000001\n",
    ")\n",
    "early_stop = EarlyStopping(\n",
    "    patience=10,\n",
    "    verbose=1,\n",
    "    monitor=\"val_accuracy\",\n",
    "    mode=\"max\",\n",
    "    min_delta=0.001,\n",
    "    restore_best_weights=True,\n",
    ")\n",
    "history = model11.fit_generator(train_data_gen, validation_data=val_data_gen, epochs=200,callbacks=[learning_rate_reduction, early_stop],)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg_acc = history.history[\"val_accuracy\"]\n",
    "#vgg_prec = history.history[\"val_precision_m\"]\n",
    "#vgg_rec = history.history[\"val_recall_m\"]\n",
    "#vgg_f1 = history.history[\"val_f1_m\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(2, 1)\n",
    "ax1.plot(history.history[\"loss\"], color=\"b\", label=\"Training loss\")\n",
    "ax1.plot(history.history[\"val_loss\"], color=\"r\", label=\"validation loss\")\n",
    "ax1.legend()\n",
    "\n",
    "ax2.plot(history.history[\"accuracy\"], color=\"b\", label=\"Training accuracy\")\n",
    "ax2.plot(history.history[\"val_accuracy\"], color=\"r\", label=\"Validation accuracy\")\n",
    "ax2.legend()\n",
    "\n",
    "legend = plt.legend(loc=\"best\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ResNet101"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.resnet import ResNet101"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            [(None, 128, 128, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1_pad (ZeroPadding2D)       (None, 134, 134, 3)  0           input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1_conv (Conv2D)             (None, 64, 64, 64)   9472        conv1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1_bn (BatchNormalization)   (None, 64, 64, 64)   256         conv1_conv[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1_relu (Activation)         (None, 64, 64, 64)   0           conv1_bn[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pad (ZeroPadding2D)       (None, 66, 66, 64)   0           conv1_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pool (MaxPooling2D)       (None, 32, 32, 64)   0           pool1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_conv (Conv2D)    (None, 32, 32, 64)   4160        pool1_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_bn (BatchNormali (None, 32, 32, 64)   256         conv2_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_relu (Activation (None, 32, 32, 64)   0           conv2_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_conv (Conv2D)    (None, 32, 32, 64)   36928       conv2_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_bn (BatchNormali (None, 32, 32, 64)   256         conv2_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_relu (Activation (None, 32, 32, 64)   0           conv2_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_0_conv (Conv2D)    (None, 32, 32, 256)  16640       pool1_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_3_conv (Conv2D)    (None, 32, 32, 256)  16640       conv2_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_0_bn (BatchNormali (None, 32, 32, 256)  1024        conv2_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_3_bn (BatchNormali (None, 32, 32, 256)  1024        conv2_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_add (Add)          (None, 32, 32, 256)  0           conv2_block1_0_bn[0][0]          \n",
      "                                                                 conv2_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_out (Activation)   (None, 32, 32, 256)  0           conv2_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_conv (Conv2D)    (None, 32, 32, 64)   16448       conv2_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_bn (BatchNormali (None, 32, 32, 64)   256         conv2_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_relu (Activation (None, 32, 32, 64)   0           conv2_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_conv (Conv2D)    (None, 32, 32, 64)   36928       conv2_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_bn (BatchNormali (None, 32, 32, 64)   256         conv2_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_relu (Activation (None, 32, 32, 64)   0           conv2_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_3_conv (Conv2D)    (None, 32, 32, 256)  16640       conv2_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_3_bn (BatchNormali (None, 32, 32, 256)  1024        conv2_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_add (Add)          (None, 32, 32, 256)  0           conv2_block1_out[0][0]           \n",
      "                                                                 conv2_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_out (Activation)   (None, 32, 32, 256)  0           conv2_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_conv (Conv2D)    (None, 32, 32, 64)   16448       conv2_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_bn (BatchNormali (None, 32, 32, 64)   256         conv2_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_relu (Activation (None, 32, 32, 64)   0           conv2_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_conv (Conv2D)    (None, 32, 32, 64)   36928       conv2_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_bn (BatchNormali (None, 32, 32, 64)   256         conv2_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_relu (Activation (None, 32, 32, 64)   0           conv2_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_3_conv (Conv2D)    (None, 32, 32, 256)  16640       conv2_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_3_bn (BatchNormali (None, 32, 32, 256)  1024        conv2_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_add (Add)          (None, 32, 32, 256)  0           conv2_block2_out[0][0]           \n",
      "                                                                 conv2_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_out (Activation)   (None, 32, 32, 256)  0           conv2_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_conv (Conv2D)    (None, 16, 16, 128)  32896       conv2_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_bn (BatchNormali (None, 16, 16, 128)  512         conv3_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_relu (Activation (None, 16, 16, 128)  0           conv3_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_conv (Conv2D)    (None, 16, 16, 128)  147584      conv3_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_bn (BatchNormali (None, 16, 16, 128)  512         conv3_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_relu (Activation (None, 16, 16, 128)  0           conv3_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_0_conv (Conv2D)    (None, 16, 16, 512)  131584      conv2_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_3_conv (Conv2D)    (None, 16, 16, 512)  66048       conv3_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_0_bn (BatchNormali (None, 16, 16, 512)  2048        conv3_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_3_bn (BatchNormali (None, 16, 16, 512)  2048        conv3_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_add (Add)          (None, 16, 16, 512)  0           conv3_block1_0_bn[0][0]          \n",
      "                                                                 conv3_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_out (Activation)   (None, 16, 16, 512)  0           conv3_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_conv (Conv2D)    (None, 16, 16, 128)  65664       conv3_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_bn (BatchNormali (None, 16, 16, 128)  512         conv3_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_relu (Activation (None, 16, 16, 128)  0           conv3_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_conv (Conv2D)    (None, 16, 16, 128)  147584      conv3_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_bn (BatchNormali (None, 16, 16, 128)  512         conv3_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_relu (Activation (None, 16, 16, 128)  0           conv3_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_3_conv (Conv2D)    (None, 16, 16, 512)  66048       conv3_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_3_bn (BatchNormali (None, 16, 16, 512)  2048        conv3_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_add (Add)          (None, 16, 16, 512)  0           conv3_block1_out[0][0]           \n",
      "                                                                 conv3_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_out (Activation)   (None, 16, 16, 512)  0           conv3_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_conv (Conv2D)    (None, 16, 16, 128)  65664       conv3_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_bn (BatchNormali (None, 16, 16, 128)  512         conv3_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_relu (Activation (None, 16, 16, 128)  0           conv3_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_conv (Conv2D)    (None, 16, 16, 128)  147584      conv3_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_bn (BatchNormali (None, 16, 16, 128)  512         conv3_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_relu (Activation (None, 16, 16, 128)  0           conv3_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_3_conv (Conv2D)    (None, 16, 16, 512)  66048       conv3_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_3_bn (BatchNormali (None, 16, 16, 512)  2048        conv3_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_add (Add)          (None, 16, 16, 512)  0           conv3_block2_out[0][0]           \n",
      "                                                                 conv3_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_out (Activation)   (None, 16, 16, 512)  0           conv3_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_conv (Conv2D)    (None, 16, 16, 128)  65664       conv3_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_bn (BatchNormali (None, 16, 16, 128)  512         conv3_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_relu (Activation (None, 16, 16, 128)  0           conv3_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_conv (Conv2D)    (None, 16, 16, 128)  147584      conv3_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_bn (BatchNormali (None, 16, 16, 128)  512         conv3_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_relu (Activation (None, 16, 16, 128)  0           conv3_block4_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_3_conv (Conv2D)    (None, 16, 16, 512)  66048       conv3_block4_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_3_bn (BatchNormali (None, 16, 16, 512)  2048        conv3_block4_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_add (Add)          (None, 16, 16, 512)  0           conv3_block3_out[0][0]           \n",
      "                                                                 conv3_block4_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_out (Activation)   (None, 16, 16, 512)  0           conv3_block4_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_conv (Conv2D)    (None, 8, 8, 256)    131328      conv3_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_bn (BatchNormali (None, 8, 8, 256)    1024        conv4_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_relu (Activation (None, 8, 8, 256)    0           conv4_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_conv (Conv2D)    (None, 8, 8, 256)    590080      conv4_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_bn (BatchNormali (None, 8, 8, 256)    1024        conv4_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_relu (Activation (None, 8, 8, 256)    0           conv4_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_0_conv (Conv2D)    (None, 8, 8, 1024)   525312      conv3_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_3_conv (Conv2D)    (None, 8, 8, 1024)   263168      conv4_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_0_bn (BatchNormali (None, 8, 8, 1024)   4096        conv4_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_3_bn (BatchNormali (None, 8, 8, 1024)   4096        conv4_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_add (Add)          (None, 8, 8, 1024)   0           conv4_block1_0_bn[0][0]          \n",
      "                                                                 conv4_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_out (Activation)   (None, 8, 8, 1024)   0           conv4_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_conv (Conv2D)    (None, 8, 8, 256)    262400      conv4_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_bn (BatchNormali (None, 8, 8, 256)    1024        conv4_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_relu (Activation (None, 8, 8, 256)    0           conv4_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_conv (Conv2D)    (None, 8, 8, 256)    590080      conv4_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_bn (BatchNormali (None, 8, 8, 256)    1024        conv4_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_relu (Activation (None, 8, 8, 256)    0           conv4_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_3_conv (Conv2D)    (None, 8, 8, 1024)   263168      conv4_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_3_bn (BatchNormali (None, 8, 8, 1024)   4096        conv4_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_add (Add)          (None, 8, 8, 1024)   0           conv4_block1_out[0][0]           \n",
      "                                                                 conv4_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_out (Activation)   (None, 8, 8, 1024)   0           conv4_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_conv (Conv2D)    (None, 8, 8, 256)    262400      conv4_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_bn (BatchNormali (None, 8, 8, 256)    1024        conv4_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_relu (Activation (None, 8, 8, 256)    0           conv4_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_conv (Conv2D)    (None, 8, 8, 256)    590080      conv4_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_bn (BatchNormali (None, 8, 8, 256)    1024        conv4_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_relu (Activation (None, 8, 8, 256)    0           conv4_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_3_conv (Conv2D)    (None, 8, 8, 1024)   263168      conv4_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_3_bn (BatchNormali (None, 8, 8, 1024)   4096        conv4_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_add (Add)          (None, 8, 8, 1024)   0           conv4_block2_out[0][0]           \n",
      "                                                                 conv4_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_out (Activation)   (None, 8, 8, 1024)   0           conv4_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_conv (Conv2D)    (None, 8, 8, 256)    262400      conv4_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_bn (BatchNormali (None, 8, 8, 256)    1024        conv4_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_relu (Activation (None, 8, 8, 256)    0           conv4_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_conv (Conv2D)    (None, 8, 8, 256)    590080      conv4_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_bn (BatchNormali (None, 8, 8, 256)    1024        conv4_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_relu (Activation (None, 8, 8, 256)    0           conv4_block4_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_3_conv (Conv2D)    (None, 8, 8, 1024)   263168      conv4_block4_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_3_bn (BatchNormali (None, 8, 8, 1024)   4096        conv4_block4_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_add (Add)          (None, 8, 8, 1024)   0           conv4_block3_out[0][0]           \n",
      "                                                                 conv4_block4_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_out (Activation)   (None, 8, 8, 1024)   0           conv4_block4_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_conv (Conv2D)    (None, 8, 8, 256)    262400      conv4_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_bn (BatchNormali (None, 8, 8, 256)    1024        conv4_block5_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_relu (Activation (None, 8, 8, 256)    0           conv4_block5_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_conv (Conv2D)    (None, 8, 8, 256)    590080      conv4_block5_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_bn (BatchNormali (None, 8, 8, 256)    1024        conv4_block5_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_relu (Activation (None, 8, 8, 256)    0           conv4_block5_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_3_conv (Conv2D)    (None, 8, 8, 1024)   263168      conv4_block5_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_3_bn (BatchNormali (None, 8, 8, 1024)   4096        conv4_block5_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_add (Add)          (None, 8, 8, 1024)   0           conv4_block4_out[0][0]           \n",
      "                                                                 conv4_block5_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_out (Activation)   (None, 8, 8, 1024)   0           conv4_block5_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_conv (Conv2D)    (None, 8, 8, 256)    262400      conv4_block5_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_bn (BatchNormali (None, 8, 8, 256)    1024        conv4_block6_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_relu (Activation (None, 8, 8, 256)    0           conv4_block6_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_conv (Conv2D)    (None, 8, 8, 256)    590080      conv4_block6_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_bn (BatchNormali (None, 8, 8, 256)    1024        conv4_block6_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_relu (Activation (None, 8, 8, 256)    0           conv4_block6_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_3_conv (Conv2D)    (None, 8, 8, 1024)   263168      conv4_block6_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_3_bn (BatchNormali (None, 8, 8, 1024)   4096        conv4_block6_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_add (Add)          (None, 8, 8, 1024)   0           conv4_block5_out[0][0]           \n",
      "                                                                 conv4_block6_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_out (Activation)   (None, 8, 8, 1024)   0           conv4_block6_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_1_conv (Conv2D)    (None, 8, 8, 256)    262400      conv4_block6_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_1_bn (BatchNormali (None, 8, 8, 256)    1024        conv4_block7_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_1_relu (Activation (None, 8, 8, 256)    0           conv4_block7_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_2_conv (Conv2D)    (None, 8, 8, 256)    590080      conv4_block7_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_2_bn (BatchNormali (None, 8, 8, 256)    1024        conv4_block7_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_2_relu (Activation (None, 8, 8, 256)    0           conv4_block7_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_3_conv (Conv2D)    (None, 8, 8, 1024)   263168      conv4_block7_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_3_bn (BatchNormali (None, 8, 8, 1024)   4096        conv4_block7_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_add (Add)          (None, 8, 8, 1024)   0           conv4_block6_out[0][0]           \n",
      "                                                                 conv4_block7_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_out (Activation)   (None, 8, 8, 1024)   0           conv4_block7_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_1_conv (Conv2D)    (None, 8, 8, 256)    262400      conv4_block7_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_1_bn (BatchNormali (None, 8, 8, 256)    1024        conv4_block8_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_1_relu (Activation (None, 8, 8, 256)    0           conv4_block8_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_2_conv (Conv2D)    (None, 8, 8, 256)    590080      conv4_block8_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_2_bn (BatchNormali (None, 8, 8, 256)    1024        conv4_block8_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_2_relu (Activation (None, 8, 8, 256)    0           conv4_block8_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_3_conv (Conv2D)    (None, 8, 8, 1024)   263168      conv4_block8_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_3_bn (BatchNormali (None, 8, 8, 1024)   4096        conv4_block8_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_add (Add)          (None, 8, 8, 1024)   0           conv4_block7_out[0][0]           \n",
      "                                                                 conv4_block8_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_out (Activation)   (None, 8, 8, 1024)   0           conv4_block8_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_1_conv (Conv2D)    (None, 8, 8, 256)    262400      conv4_block8_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_1_bn (BatchNormali (None, 8, 8, 256)    1024        conv4_block9_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_1_relu (Activation (None, 8, 8, 256)    0           conv4_block9_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_2_conv (Conv2D)    (None, 8, 8, 256)    590080      conv4_block9_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_2_bn (BatchNormali (None, 8, 8, 256)    1024        conv4_block9_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_2_relu (Activation (None, 8, 8, 256)    0           conv4_block9_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_3_conv (Conv2D)    (None, 8, 8, 1024)   263168      conv4_block9_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_3_bn (BatchNormali (None, 8, 8, 1024)   4096        conv4_block9_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_add (Add)          (None, 8, 8, 1024)   0           conv4_block8_out[0][0]           \n",
      "                                                                 conv4_block9_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_out (Activation)   (None, 8, 8, 1024)   0           conv4_block9_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_1_conv (Conv2D)   (None, 8, 8, 256)    262400      conv4_block9_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_1_bn (BatchNormal (None, 8, 8, 256)    1024        conv4_block10_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_1_relu (Activatio (None, 8, 8, 256)    0           conv4_block10_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_2_conv (Conv2D)   (None, 8, 8, 256)    590080      conv4_block10_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_2_bn (BatchNormal (None, 8, 8, 256)    1024        conv4_block10_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_2_relu (Activatio (None, 8, 8, 256)    0           conv4_block10_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_3_conv (Conv2D)   (None, 8, 8, 1024)   263168      conv4_block10_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_3_bn (BatchNormal (None, 8, 8, 1024)   4096        conv4_block10_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_add (Add)         (None, 8, 8, 1024)   0           conv4_block9_out[0][0]           \n",
      "                                                                 conv4_block10_3_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_out (Activation)  (None, 8, 8, 1024)   0           conv4_block10_add[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_1_conv (Conv2D)   (None, 8, 8, 256)    262400      conv4_block10_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_1_bn (BatchNormal (None, 8, 8, 256)    1024        conv4_block11_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_1_relu (Activatio (None, 8, 8, 256)    0           conv4_block11_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_2_conv (Conv2D)   (None, 8, 8, 256)    590080      conv4_block11_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_2_bn (BatchNormal (None, 8, 8, 256)    1024        conv4_block11_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_2_relu (Activatio (None, 8, 8, 256)    0           conv4_block11_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_3_conv (Conv2D)   (None, 8, 8, 1024)   263168      conv4_block11_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_3_bn (BatchNormal (None, 8, 8, 1024)   4096        conv4_block11_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_add (Add)         (None, 8, 8, 1024)   0           conv4_block10_out[0][0]          \n",
      "                                                                 conv4_block11_3_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_out (Activation)  (None, 8, 8, 1024)   0           conv4_block11_add[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_1_conv (Conv2D)   (None, 8, 8, 256)    262400      conv4_block11_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_1_bn (BatchNormal (None, 8, 8, 256)    1024        conv4_block12_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_1_relu (Activatio (None, 8, 8, 256)    0           conv4_block12_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_2_conv (Conv2D)   (None, 8, 8, 256)    590080      conv4_block12_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_2_bn (BatchNormal (None, 8, 8, 256)    1024        conv4_block12_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_2_relu (Activatio (None, 8, 8, 256)    0           conv4_block12_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_3_conv (Conv2D)   (None, 8, 8, 1024)   263168      conv4_block12_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_3_bn (BatchNormal (None, 8, 8, 1024)   4096        conv4_block12_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_add (Add)         (None, 8, 8, 1024)   0           conv4_block11_out[0][0]          \n",
      "                                                                 conv4_block12_3_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_out (Activation)  (None, 8, 8, 1024)   0           conv4_block12_add[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_1_conv (Conv2D)   (None, 8, 8, 256)    262400      conv4_block12_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_1_bn (BatchNormal (None, 8, 8, 256)    1024        conv4_block13_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_1_relu (Activatio (None, 8, 8, 256)    0           conv4_block13_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_2_conv (Conv2D)   (None, 8, 8, 256)    590080      conv4_block13_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_2_bn (BatchNormal (None, 8, 8, 256)    1024        conv4_block13_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_2_relu (Activatio (None, 8, 8, 256)    0           conv4_block13_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_3_conv (Conv2D)   (None, 8, 8, 1024)   263168      conv4_block13_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_3_bn (BatchNormal (None, 8, 8, 1024)   4096        conv4_block13_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_add (Add)         (None, 8, 8, 1024)   0           conv4_block12_out[0][0]          \n",
      "                                                                 conv4_block13_3_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_out (Activation)  (None, 8, 8, 1024)   0           conv4_block13_add[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_1_conv (Conv2D)   (None, 8, 8, 256)    262400      conv4_block13_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_1_bn (BatchNormal (None, 8, 8, 256)    1024        conv4_block14_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_1_relu (Activatio (None, 8, 8, 256)    0           conv4_block14_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_2_conv (Conv2D)   (None, 8, 8, 256)    590080      conv4_block14_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_2_bn (BatchNormal (None, 8, 8, 256)    1024        conv4_block14_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_2_relu (Activatio (None, 8, 8, 256)    0           conv4_block14_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_3_conv (Conv2D)   (None, 8, 8, 1024)   263168      conv4_block14_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_3_bn (BatchNormal (None, 8, 8, 1024)   4096        conv4_block14_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_add (Add)         (None, 8, 8, 1024)   0           conv4_block13_out[0][0]          \n",
      "                                                                 conv4_block14_3_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_out (Activation)  (None, 8, 8, 1024)   0           conv4_block14_add[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_1_conv (Conv2D)   (None, 8, 8, 256)    262400      conv4_block14_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_1_bn (BatchNormal (None, 8, 8, 256)    1024        conv4_block15_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_1_relu (Activatio (None, 8, 8, 256)    0           conv4_block15_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_2_conv (Conv2D)   (None, 8, 8, 256)    590080      conv4_block15_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_2_bn (BatchNormal (None, 8, 8, 256)    1024        conv4_block15_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_2_relu (Activatio (None, 8, 8, 256)    0           conv4_block15_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_3_conv (Conv2D)   (None, 8, 8, 1024)   263168      conv4_block15_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_3_bn (BatchNormal (None, 8, 8, 1024)   4096        conv4_block15_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_add (Add)         (None, 8, 8, 1024)   0           conv4_block14_out[0][0]          \n",
      "                                                                 conv4_block15_3_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_out (Activation)  (None, 8, 8, 1024)   0           conv4_block15_add[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_1_conv (Conv2D)   (None, 8, 8, 256)    262400      conv4_block15_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_1_bn (BatchNormal (None, 8, 8, 256)    1024        conv4_block16_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_1_relu (Activatio (None, 8, 8, 256)    0           conv4_block16_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_2_conv (Conv2D)   (None, 8, 8, 256)    590080      conv4_block16_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_2_bn (BatchNormal (None, 8, 8, 256)    1024        conv4_block16_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_2_relu (Activatio (None, 8, 8, 256)    0           conv4_block16_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_3_conv (Conv2D)   (None, 8, 8, 1024)   263168      conv4_block16_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_3_bn (BatchNormal (None, 8, 8, 1024)   4096        conv4_block16_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_add (Add)         (None, 8, 8, 1024)   0           conv4_block15_out[0][0]          \n",
      "                                                                 conv4_block16_3_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_out (Activation)  (None, 8, 8, 1024)   0           conv4_block16_add[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_1_conv (Conv2D)   (None, 8, 8, 256)    262400      conv4_block16_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_1_bn (BatchNormal (None, 8, 8, 256)    1024        conv4_block17_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_1_relu (Activatio (None, 8, 8, 256)    0           conv4_block17_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_2_conv (Conv2D)   (None, 8, 8, 256)    590080      conv4_block17_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_2_bn (BatchNormal (None, 8, 8, 256)    1024        conv4_block17_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_2_relu (Activatio (None, 8, 8, 256)    0           conv4_block17_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_3_conv (Conv2D)   (None, 8, 8, 1024)   263168      conv4_block17_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_3_bn (BatchNormal (None, 8, 8, 1024)   4096        conv4_block17_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_add (Add)         (None, 8, 8, 1024)   0           conv4_block16_out[0][0]          \n",
      "                                                                 conv4_block17_3_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_out (Activation)  (None, 8, 8, 1024)   0           conv4_block17_add[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_1_conv (Conv2D)   (None, 8, 8, 256)    262400      conv4_block17_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_1_bn (BatchNormal (None, 8, 8, 256)    1024        conv4_block18_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_1_relu (Activatio (None, 8, 8, 256)    0           conv4_block18_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_2_conv (Conv2D)   (None, 8, 8, 256)    590080      conv4_block18_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_2_bn (BatchNormal (None, 8, 8, 256)    1024        conv4_block18_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_2_relu (Activatio (None, 8, 8, 256)    0           conv4_block18_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_3_conv (Conv2D)   (None, 8, 8, 1024)   263168      conv4_block18_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_3_bn (BatchNormal (None, 8, 8, 1024)   4096        conv4_block18_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_add (Add)         (None, 8, 8, 1024)   0           conv4_block17_out[0][0]          \n",
      "                                                                 conv4_block18_3_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_out (Activation)  (None, 8, 8, 1024)   0           conv4_block18_add[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_1_conv (Conv2D)   (None, 8, 8, 256)    262400      conv4_block18_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_1_bn (BatchNormal (None, 8, 8, 256)    1024        conv4_block19_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_1_relu (Activatio (None, 8, 8, 256)    0           conv4_block19_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_2_conv (Conv2D)   (None, 8, 8, 256)    590080      conv4_block19_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_2_bn (BatchNormal (None, 8, 8, 256)    1024        conv4_block19_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_2_relu (Activatio (None, 8, 8, 256)    0           conv4_block19_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_3_conv (Conv2D)   (None, 8, 8, 1024)   263168      conv4_block19_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_3_bn (BatchNormal (None, 8, 8, 1024)   4096        conv4_block19_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_add (Add)         (None, 8, 8, 1024)   0           conv4_block18_out[0][0]          \n",
      "                                                                 conv4_block19_3_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_out (Activation)  (None, 8, 8, 1024)   0           conv4_block19_add[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_1_conv (Conv2D)   (None, 8, 8, 256)    262400      conv4_block19_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_1_bn (BatchNormal (None, 8, 8, 256)    1024        conv4_block20_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_1_relu (Activatio (None, 8, 8, 256)    0           conv4_block20_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_2_conv (Conv2D)   (None, 8, 8, 256)    590080      conv4_block20_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_2_bn (BatchNormal (None, 8, 8, 256)    1024        conv4_block20_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_2_relu (Activatio (None, 8, 8, 256)    0           conv4_block20_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_3_conv (Conv2D)   (None, 8, 8, 1024)   263168      conv4_block20_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_3_bn (BatchNormal (None, 8, 8, 1024)   4096        conv4_block20_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_add (Add)         (None, 8, 8, 1024)   0           conv4_block19_out[0][0]          \n",
      "                                                                 conv4_block20_3_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_out (Activation)  (None, 8, 8, 1024)   0           conv4_block20_add[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_1_conv (Conv2D)   (None, 8, 8, 256)    262400      conv4_block20_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_1_bn (BatchNormal (None, 8, 8, 256)    1024        conv4_block21_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_1_relu (Activatio (None, 8, 8, 256)    0           conv4_block21_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_2_conv (Conv2D)   (None, 8, 8, 256)    590080      conv4_block21_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_2_bn (BatchNormal (None, 8, 8, 256)    1024        conv4_block21_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_2_relu (Activatio (None, 8, 8, 256)    0           conv4_block21_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_3_conv (Conv2D)   (None, 8, 8, 1024)   263168      conv4_block21_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_3_bn (BatchNormal (None, 8, 8, 1024)   4096        conv4_block21_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_add (Add)         (None, 8, 8, 1024)   0           conv4_block20_out[0][0]          \n",
      "                                                                 conv4_block21_3_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_out (Activation)  (None, 8, 8, 1024)   0           conv4_block21_add[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_1_conv (Conv2D)   (None, 8, 8, 256)    262400      conv4_block21_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_1_bn (BatchNormal (None, 8, 8, 256)    1024        conv4_block22_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_1_relu (Activatio (None, 8, 8, 256)    0           conv4_block22_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_2_conv (Conv2D)   (None, 8, 8, 256)    590080      conv4_block22_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_2_bn (BatchNormal (None, 8, 8, 256)    1024        conv4_block22_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_2_relu (Activatio (None, 8, 8, 256)    0           conv4_block22_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_3_conv (Conv2D)   (None, 8, 8, 1024)   263168      conv4_block22_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_3_bn (BatchNormal (None, 8, 8, 1024)   4096        conv4_block22_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_add (Add)         (None, 8, 8, 1024)   0           conv4_block21_out[0][0]          \n",
      "                                                                 conv4_block22_3_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_out (Activation)  (None, 8, 8, 1024)   0           conv4_block22_add[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_1_conv (Conv2D)   (None, 8, 8, 256)    262400      conv4_block22_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_1_bn (BatchNormal (None, 8, 8, 256)    1024        conv4_block23_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_1_relu (Activatio (None, 8, 8, 256)    0           conv4_block23_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_2_conv (Conv2D)   (None, 8, 8, 256)    590080      conv4_block23_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_2_bn (BatchNormal (None, 8, 8, 256)    1024        conv4_block23_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_2_relu (Activatio (None, 8, 8, 256)    0           conv4_block23_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_3_conv (Conv2D)   (None, 8, 8, 1024)   263168      conv4_block23_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_3_bn (BatchNormal (None, 8, 8, 1024)   4096        conv4_block23_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_add (Add)         (None, 8, 8, 1024)   0           conv4_block22_out[0][0]          \n",
      "                                                                 conv4_block23_3_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_out (Activation)  (None, 8, 8, 1024)   0           conv4_block23_add[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_conv (Conv2D)    (None, 4, 4, 512)    524800      conv4_block23_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_bn (BatchNormali (None, 4, 4, 512)    2048        conv5_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_relu (Activation (None, 4, 4, 512)    0           conv5_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_conv (Conv2D)    (None, 4, 4, 512)    2359808     conv5_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_bn (BatchNormali (None, 4, 4, 512)    2048        conv5_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_relu (Activation (None, 4, 4, 512)    0           conv5_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_0_conv (Conv2D)    (None, 4, 4, 2048)   2099200     conv4_block23_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_3_conv (Conv2D)    (None, 4, 4, 2048)   1050624     conv5_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_0_bn (BatchNormali (None, 4, 4, 2048)   8192        conv5_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_3_bn (BatchNormali (None, 4, 4, 2048)   8192        conv5_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_add (Add)          (None, 4, 4, 2048)   0           conv5_block1_0_bn[0][0]          \n",
      "                                                                 conv5_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_out (Activation)   (None, 4, 4, 2048)   0           conv5_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_conv (Conv2D)    (None, 4, 4, 512)    1049088     conv5_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_bn (BatchNormali (None, 4, 4, 512)    2048        conv5_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_relu (Activation (None, 4, 4, 512)    0           conv5_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_conv (Conv2D)    (None, 4, 4, 512)    2359808     conv5_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_bn (BatchNormali (None, 4, 4, 512)    2048        conv5_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_relu (Activation (None, 4, 4, 512)    0           conv5_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_3_conv (Conv2D)    (None, 4, 4, 2048)   1050624     conv5_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_3_bn (BatchNormali (None, 4, 4, 2048)   8192        conv5_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_add (Add)          (None, 4, 4, 2048)   0           conv5_block1_out[0][0]           \n",
      "                                                                 conv5_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_out (Activation)   (None, 4, 4, 2048)   0           conv5_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_conv (Conv2D)    (None, 4, 4, 512)    1049088     conv5_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_bn (BatchNormali (None, 4, 4, 512)    2048        conv5_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_relu (Activation (None, 4, 4, 512)    0           conv5_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_conv (Conv2D)    (None, 4, 4, 512)    2359808     conv5_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_bn (BatchNormali (None, 4, 4, 512)    2048        conv5_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_relu (Activation (None, 4, 4, 512)    0           conv5_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_3_conv (Conv2D)    (None, 4, 4, 2048)   1050624     conv5_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_3_bn (BatchNormali (None, 4, 4, 2048)   8192        conv5_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_add (Add)          (None, 4, 4, 2048)   0           conv5_block2_out[0][0]           \n",
      "                                                                 conv5_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_out (Activation)   (None, 4, 4, 2048)   0           conv5_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 32768)        0           conv5_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 2)            65538       flatten_1[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 42,723,714\n",
      "Trainable params: 42,618,370\n",
      "Non-trainable params: 105,344\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "res = ResNet101(input_shape = IMAGE_SIZE + [3], weights='imagenet', include_top=False)\n",
    "x11= Flatten()(res.output)\n",
    "prediction11 = Dense(2, activation='softmax')(x11)\n",
    "model1 = Model(inputs = res.inputs, outputs = prediction11)\n",
    "model1.summary()\n",
    "model1.compile(loss = 'categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "45/45 [==============================] - 732s 15s/step - loss: 0.5257 - accuracy: 0.9333 - val_loss: 3669915.7500 - val_accuracy: 0.5000\n",
      "Epoch 2/200\n",
      "45/45 [==============================] - 679s 15s/step - loss: 1.7744 - accuracy: 0.9215 - val_loss: 7551668715520.0000 - val_accuracy: 0.5000\n",
      "Epoch 3/200\n",
      "45/45 [==============================] - 678s 15s/step - loss: 2.1091 - accuracy: 0.8701 - val_loss: 394639936.0000 - val_accuracy: 0.5000\n",
      "Epoch 4/200\n",
      "45/45 [==============================] - 634s 14s/step - loss: 1.6445 - accuracy: 0.9049 - val_loss: 55657.9336 - val_accuracy: 0.5056\n",
      "Epoch 5/200\n",
      "45/45 [==============================] - 665s 15s/step - loss: 0.1445 - accuracy: 0.9500 - val_loss: 122.2568 - val_accuracy: 0.6222\n",
      "Epoch 6/200\n",
      "45/45 [==============================] - 678s 15s/step - loss: 0.0693 - accuracy: 0.9792 - val_loss: 17.6263 - val_accuracy: 0.7250\n",
      "Epoch 7/200\n",
      "45/45 [==============================] - 670s 15s/step - loss: 0.0565 - accuracy: 0.9882 - val_loss: 5.8503 - val_accuracy: 0.7861\n",
      "Epoch 8/200\n",
      "45/45 [==============================] - 467s 10s/step - loss: 0.0537 - accuracy: 0.9847 - val_loss: 1.1403 - val_accuracy: 0.7889\n",
      "Epoch 9/200\n",
      "45/45 [==============================] - 370s 8s/step - loss: 0.0375 - accuracy: 0.9882 - val_loss: 0.5885 - val_accuracy: 0.8500\n",
      "Epoch 10/200\n",
      "45/45 [==============================] - 364s 8s/step - loss: 0.0173 - accuracy: 0.9986 - val_loss: 0.6537 - val_accuracy: 0.8222\n",
      "Epoch 11/200\n",
      "45/45 [==============================] - 370s 8s/step - loss: 0.0110 - accuracy: 0.9993 - val_loss: 0.5514 - val_accuracy: 0.8333\n",
      "Epoch 12/200\n",
      "45/45 [==============================] - 373s 8s/step - loss: 0.0081 - accuracy: 0.9993 - val_loss: 0.5219 - val_accuracy: 0.8306\n",
      "\n",
      "Epoch 00012: ReduceLROnPlateau reducing learning rate to 0.0003000000142492354.\n",
      "Epoch 13/200\n",
      "45/45 [==============================] - 373s 8s/step - loss: 0.0073 - accuracy: 0.9993 - val_loss: 0.5452 - val_accuracy: 0.8306\n",
      "Epoch 14/200\n",
      "45/45 [==============================] - 374s 8s/step - loss: 0.0067 - accuracy: 0.9993 - val_loss: 0.5216 - val_accuracy: 0.8306\n",
      "Epoch 15/200\n",
      "45/45 [==============================] - 374s 8s/step - loss: 0.0064 - accuracy: 1.0000 - val_loss: 0.5340 - val_accuracy: 0.8444\n",
      "\n",
      "Epoch 00015: ReduceLROnPlateau reducing learning rate to 9.000000427477062e-05.\n",
      "Epoch 16/200\n",
      "45/45 [==============================] - 369s 8s/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 0.5485 - val_accuracy: 0.8361\n",
      "Epoch 17/200\n",
      "45/45 [==============================] - 372s 8s/step - loss: 0.0056 - accuracy: 1.0000 - val_loss: 0.5597 - val_accuracy: 0.8444\n",
      "Epoch 18/200\n",
      "45/45 [==============================] - 372s 8s/step - loss: 0.0065 - accuracy: 0.9993 - val_loss: 0.6412 - val_accuracy: 0.8528\n",
      "Epoch 19/200\n",
      "45/45 [==============================] - 377s 8s/step - loss: 0.0064 - accuracy: 0.9993 - val_loss: 0.6376 - val_accuracy: 0.8333\n",
      "Epoch 20/200\n",
      "45/45 [==============================] - 375s 8s/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 0.6078 - val_accuracy: 0.8361\n",
      "Epoch 21/200\n",
      "45/45 [==============================] - 376s 8s/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 0.5992 - val_accuracy: 0.8361\n",
      "\n",
      "Epoch 00021: ReduceLROnPlateau reducing learning rate to 2.700000040931627e-05.\n",
      "Epoch 22/200\n",
      "45/45 [==============================] - 371s 8s/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.5991 - val_accuracy: 0.8361\n",
      "Epoch 23/200\n",
      "45/45 [==============================] - 371s 8s/step - loss: 0.0052 - accuracy: 0.9993 - val_loss: 0.5976 - val_accuracy: 0.8361\n",
      "Epoch 24/200\n",
      "45/45 [==============================] - 375s 8s/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.5984 - val_accuracy: 0.8361\n",
      "\n",
      "Epoch 00024: ReduceLROnPlateau reducing learning rate to 8.100000013655517e-06.\n",
      "Epoch 25/200\n",
      "45/45 [==============================] - 374s 8s/step - loss: 0.0051 - accuracy: 0.9993 - val_loss: 0.6001 - val_accuracy: 0.8361\n",
      "Epoch 26/200\n",
      "45/45 [==============================] - 375s 8s/step - loss: 0.0123 - accuracy: 0.9993 - val_loss: 0.5992 - val_accuracy: 0.8333\n",
      "Epoch 27/200\n",
      "45/45 [==============================] - 373s 8s/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 0.5998 - val_accuracy: 0.8333\n",
      "\n",
      "Epoch 00027: ReduceLROnPlateau reducing learning rate to 2.429999949526973e-06.\n",
      "Epoch 28/200\n",
      "45/45 [==============================] - 372s 8s/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 0.5998 - val_accuracy: 0.8333\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00028: early stopping\n"
     ]
    }
   ],
   "source": [
    "history1 = model1.fit_generator(train_data_gen, validation_data=val_data_gen, epochs=200, steps_per_epoch=len(train_data_gen), validation_steps=len(val_data_gen),callbacks=[learning_rate_reduction, early_stop],)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_acc = history1.history[\"val_accuracy\"]\n",
    "#res_prec = history1.history[\"val_precision_m\"]\n",
    "#res_rec = history1.history[\"val_recall_m\"]\n",
    "#res_f1 = history1.history[\"val_f1_m\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(2, 1)\n",
    "ax1.plot(history1.history[\"loss\"], color=\"b\", label=\"Training loss\")\n",
    "ax1.plot(history1.history[\"val_loss\"], color=\"r\", label=\"validation loss\")\n",
    "ax1.legend()\n",
    "\n",
    "ax2.plot(history1.history[\"accuracy\"], color=\"b\", label=\"Training accuracy\")\n",
    "ax2.plot(history1.history[\"val_accuracy\"], color=\"r\", label=\"Validation accuracy\")\n",
    "ax2.legend()\n",
    "\n",
    "legend = plt.legend(loc=\"best\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MobileNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import MobileNet\n",
    "mob = MobileNet(input_shape = IMAGE_SIZE + [3], weights='imagenet', include_top=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         [(None, 128, 128, 3)]     0         \n",
      "_________________________________________________________________\n",
      "conv1 (Conv2D)               (None, 64, 64, 32)        864       \n",
      "_________________________________________________________________\n",
      "conv1_bn (BatchNormalization (None, 64, 64, 32)        128       \n",
      "_________________________________________________________________\n",
      "conv1_relu (ReLU)            (None, 64, 64, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv_dw_1 (DepthwiseConv2D)  (None, 64, 64, 32)        288       \n",
      "_________________________________________________________________\n",
      "conv_dw_1_bn (BatchNormaliza (None, 64, 64, 32)        128       \n",
      "_________________________________________________________________\n",
      "conv_dw_1_relu (ReLU)        (None, 64, 64, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv_pw_1 (Conv2D)           (None, 64, 64, 64)        2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_1_bn (BatchNormaliza (None, 64, 64, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv_pw_1_relu (ReLU)        (None, 64, 64, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv_pad_2 (ZeroPadding2D)   (None, 65, 65, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv_dw_2 (DepthwiseConv2D)  (None, 32, 32, 64)        576       \n",
      "_________________________________________________________________\n",
      "conv_dw_2_bn (BatchNormaliza (None, 32, 32, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv_dw_2_relu (ReLU)        (None, 32, 32, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv_pw_2 (Conv2D)           (None, 32, 32, 128)       8192      \n",
      "_________________________________________________________________\n",
      "conv_pw_2_bn (BatchNormaliza (None, 32, 32, 128)       512       \n",
      "_________________________________________________________________\n",
      "conv_pw_2_relu (ReLU)        (None, 32, 32, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_3 (DepthwiseConv2D)  (None, 32, 32, 128)       1152      \n",
      "_________________________________________________________________\n",
      "conv_dw_3_bn (BatchNormaliza (None, 32, 32, 128)       512       \n",
      "_________________________________________________________________\n",
      "conv_dw_3_relu (ReLU)        (None, 32, 32, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_3 (Conv2D)           (None, 32, 32, 128)       16384     \n",
      "_________________________________________________________________\n",
      "conv_pw_3_bn (BatchNormaliza (None, 32, 32, 128)       512       \n",
      "_________________________________________________________________\n",
      "conv_pw_3_relu (ReLU)        (None, 32, 32, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv_pad_4 (ZeroPadding2D)   (None, 33, 33, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_4 (DepthwiseConv2D)  (None, 16, 16, 128)       1152      \n",
      "_________________________________________________________________\n",
      "conv_dw_4_bn (BatchNormaliza (None, 16, 16, 128)       512       \n",
      "_________________________________________________________________\n",
      "conv_dw_4_relu (ReLU)        (None, 16, 16, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_4 (Conv2D)           (None, 16, 16, 256)       32768     \n",
      "_________________________________________________________________\n",
      "conv_pw_4_bn (BatchNormaliza (None, 16, 16, 256)       1024      \n",
      "_________________________________________________________________\n",
      "conv_pw_4_relu (ReLU)        (None, 16, 16, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_5 (DepthwiseConv2D)  (None, 16, 16, 256)       2304      \n",
      "_________________________________________________________________\n",
      "conv_dw_5_bn (BatchNormaliza (None, 16, 16, 256)       1024      \n",
      "_________________________________________________________________\n",
      "conv_dw_5_relu (ReLU)        (None, 16, 16, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_5 (Conv2D)           (None, 16, 16, 256)       65536     \n",
      "_________________________________________________________________\n",
      "conv_pw_5_bn (BatchNormaliza (None, 16, 16, 256)       1024      \n",
      "_________________________________________________________________\n",
      "conv_pw_5_relu (ReLU)        (None, 16, 16, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv_pad_6 (ZeroPadding2D)   (None, 17, 17, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_6 (DepthwiseConv2D)  (None, 8, 8, 256)         2304      \n",
      "_________________________________________________________________\n",
      "conv_dw_6_bn (BatchNormaliza (None, 8, 8, 256)         1024      \n",
      "_________________________________________________________________\n",
      "conv_dw_6_relu (ReLU)        (None, 8, 8, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv_pw_6 (Conv2D)           (None, 8, 8, 512)         131072    \n",
      "_________________________________________________________________\n",
      "conv_pw_6_bn (BatchNormaliza (None, 8, 8, 512)         2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_6_relu (ReLU)        (None, 8, 8, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv_dw_7 (DepthwiseConv2D)  (None, 8, 8, 512)         4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_7_bn (BatchNormaliza (None, 8, 8, 512)         2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_7_relu (ReLU)        (None, 8, 8, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv_pw_7 (Conv2D)           (None, 8, 8, 512)         262144    \n",
      "_________________________________________________________________\n",
      "conv_pw_7_bn (BatchNormaliza (None, 8, 8, 512)         2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_7_relu (ReLU)        (None, 8, 8, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv_dw_8 (DepthwiseConv2D)  (None, 8, 8, 512)         4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_8_bn (BatchNormaliza (None, 8, 8, 512)         2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_8_relu (ReLU)        (None, 8, 8, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv_pw_8 (Conv2D)           (None, 8, 8, 512)         262144    \n",
      "_________________________________________________________________\n",
      "conv_pw_8_bn (BatchNormaliza (None, 8, 8, 512)         2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_8_relu (ReLU)        (None, 8, 8, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv_dw_9 (DepthwiseConv2D)  (None, 8, 8, 512)         4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_9_bn (BatchNormaliza (None, 8, 8, 512)         2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_9_relu (ReLU)        (None, 8, 8, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv_pw_9 (Conv2D)           (None, 8, 8, 512)         262144    \n",
      "_________________________________________________________________\n",
      "conv_pw_9_bn (BatchNormaliza (None, 8, 8, 512)         2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_9_relu (ReLU)        (None, 8, 8, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv_dw_10 (DepthwiseConv2D) (None, 8, 8, 512)         4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_10_bn (BatchNormaliz (None, 8, 8, 512)         2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_10_relu (ReLU)       (None, 8, 8, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv_pw_10 (Conv2D)          (None, 8, 8, 512)         262144    \n",
      "_________________________________________________________________\n",
      "conv_pw_10_bn (BatchNormaliz (None, 8, 8, 512)         2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_10_relu (ReLU)       (None, 8, 8, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv_dw_11 (DepthwiseConv2D) (None, 8, 8, 512)         4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_11_bn (BatchNormaliz (None, 8, 8, 512)         2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_11_relu (ReLU)       (None, 8, 8, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv_pw_11 (Conv2D)          (None, 8, 8, 512)         262144    \n",
      "_________________________________________________________________\n",
      "conv_pw_11_bn (BatchNormaliz (None, 8, 8, 512)         2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_11_relu (ReLU)       (None, 8, 8, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv_pad_12 (ZeroPadding2D)  (None, 9, 9, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv_dw_12 (DepthwiseConv2D) (None, 4, 4, 512)         4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_12_bn (BatchNormaliz (None, 4, 4, 512)         2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_12_relu (ReLU)       (None, 4, 4, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv_pw_12 (Conv2D)          (None, 4, 4, 1024)        524288    \n",
      "_________________________________________________________________\n",
      "conv_pw_12_bn (BatchNormaliz (None, 4, 4, 1024)        4096      \n",
      "_________________________________________________________________\n",
      "conv_pw_12_relu (ReLU)       (None, 4, 4, 1024)        0         \n",
      "_________________________________________________________________\n",
      "conv_dw_13 (DepthwiseConv2D) (None, 4, 4, 1024)        9216      \n",
      "_________________________________________________________________\n",
      "conv_dw_13_bn (BatchNormaliz (None, 4, 4, 1024)        4096      \n",
      "_________________________________________________________________\n",
      "conv_dw_13_relu (ReLU)       (None, 4, 4, 1024)        0         \n",
      "_________________________________________________________________\n",
      "conv_pw_13 (Conv2D)          (None, 4, 4, 1024)        1048576   \n",
      "_________________________________________________________________\n",
      "conv_pw_13_bn (BatchNormaliz (None, 4, 4, 1024)        4096      \n",
      "_________________________________________________________________\n",
      "conv_pw_13_relu (ReLU)       (None, 4, 4, 1024)        0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 16384)             0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 2)                 32770     \n",
      "=================================================================\n",
      "Total params: 3,261,634\n",
      "Trainable params: 3,239,746\n",
      "Non-trainable params: 21,888\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "x1= Flatten()(mob.output)\n",
    "prediction1 = Dense(2, activation='softmax')(x1)\n",
    "model12 = Model(inputs = mob.inputs, outputs = prediction1)\n",
    "model12.summary()\n",
    "model12.compile(loss = 'categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "45/45 [==============================] - 186s 4s/step - loss: 0.8000 - accuracy: 0.9312 - val_loss: 14.4496 - val_accuracy: 0.5278\n",
      "Epoch 2/200\n",
      "45/45 [==============================] - 312s 7s/step - loss: 0.2349 - accuracy: 0.9708 - val_loss: 1.2898 - val_accuracy: 0.9444\n",
      "Epoch 3/200\n",
      "45/45 [==============================] - 334s 8s/step - loss: 0.0972 - accuracy: 0.9917 - val_loss: 1.6239 - val_accuracy: 0.8722\n",
      "Epoch 4/200\n",
      "45/45 [==============================] - 351s 8s/step - loss: 0.0502 - accuracy: 0.9937 - val_loss: 9.4532 - val_accuracy: 0.7583\n",
      "Epoch 5/200\n",
      "45/45 [==============================] - 350s 8s/step - loss: 0.0914 - accuracy: 0.9896 - val_loss: 5.1540 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00005: ReduceLROnPlateau reducing learning rate to 0.0003000000142492354.\n",
      "Epoch 6/200\n",
      "45/45 [==============================] - 348s 8s/step - loss: 0.0324 - accuracy: 0.9931 - val_loss: 2.5830 - val_accuracy: 0.8861\n",
      "Epoch 7/200\n",
      "45/45 [==============================] - 351s 8s/step - loss: 0.0021 - accuracy: 0.9986 - val_loss: 1.2672 - val_accuracy: 0.9139\n",
      "Epoch 8/200\n",
      "45/45 [==============================] - 345s 8s/step - loss: 0.0012 - accuracy: 0.9993 - val_loss: 1.1077 - val_accuracy: 0.9167\n",
      "\n",
      "Epoch 00008: ReduceLROnPlateau reducing learning rate to 9.000000427477062e-05.\n",
      "Epoch 9/200\n",
      "45/45 [==============================] - 326s 7s/step - loss: 0.0033 - accuracy: 0.9993 - val_loss: 0.6995 - val_accuracy: 0.9222\n",
      "Epoch 10/200\n",
      "45/45 [==============================] - 348s 8s/step - loss: 0.0093 - accuracy: 0.9979 - val_loss: 0.7787 - val_accuracy: 0.9250\n",
      "Epoch 11/200\n",
      "45/45 [==============================] - 352s 8s/step - loss: 5.6549e-04 - accuracy: 1.0000 - val_loss: 0.6434 - val_accuracy: 0.9250\n",
      "\n",
      "Epoch 00011: ReduceLROnPlateau reducing learning rate to 2.700000040931627e-05.\n",
      "Epoch 12/200\n",
      "45/45 [==============================] - 350s 8s/step - loss: 6.2568e-04 - accuracy: 1.0000 - val_loss: 0.6032 - val_accuracy: 0.9250\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00012: early stopping\n"
     ]
    }
   ],
   "source": [
    "history2 = model12.fit_generator(train_data_gen, validation_data=val_data_gen, epochs=200, steps_per_epoch=len(train_data_gen), validation_steps=len(val_data_gen),callbacks=[learning_rate_reduction, early_stop],)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model12.save('mobilenet.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "mob_acc = history2.history[\"val_accuracy\"]\n",
    "#mob_prec = history2.history[\"val_precision_m\"]\n",
    "#mob_rec = history2.history[\"val_recall_m\"]\n",
    "#mob_f1 = history2.history[\"val_f1_m\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(2, 1)\n",
    "ax1.plot(history2.history[\"loss\"], color=\"b\", label=\"Training loss\")\n",
    "ax1.plot(history2.history[\"val_loss\"], color=\"r\", label=\"validation loss\")\n",
    "ax1.legend()\n",
    "\n",
    "ax2.plot(history2.history[\"accuracy\"], color=\"b\", label=\"Training accuracy\")\n",
    "ax2.plot(history2.history[\"val_accuracy\"], color=\"r\", label=\"Validation accuracy\")\n",
    "ax2.legend()\n",
    "\n",
    "legend = plt.legend(loc=\"best\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Xception"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications.xception import Xception\n",
    "from keras.layers import Activation, Dense,GlobalAveragePooling2D, Dropout\n",
    "from keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the pretrained base model\n",
    "base = Xception(include_top=False, weights='imagenet', input_shape=(128,128,3))\n",
    "x = base.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "# Defining the head of the model where the prediction is conducted\n",
    "head = Dense(2, activation='softmax')(x)\n",
    "# Combining base and head \n",
    "model3 = Model(inputs=base.input, outputs=head)\n",
    "\n",
    "# Compiling the model\n",
    "model3.compile(loss = keras.losses.categorical_crossentropy, optimizer= 'adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "45/45 [==============================] - 542s 10s/step - loss: 0.2845 - accuracy: 0.8917 - val_loss: 41.6588 - val_accuracy: 0.5167\n",
      "Epoch 2/200\n",
      "45/45 [==============================] - 439s 10s/step - loss: 0.0524 - accuracy: 0.9864 - val_loss: 11.0255 - val_accuracy: 0.7389\n",
      "Epoch 3/200\n",
      "45/45 [==============================] - 499s 11s/step - loss: 0.0349 - accuracy: 0.9898 - val_loss: 2.9478 - val_accuracy: 0.8611\n",
      "Epoch 4/200\n",
      "45/45 [==============================] - 508s 11s/step - loss: 0.0317 - accuracy: 0.9938 - val_loss: 13.3510 - val_accuracy: 0.5500\n",
      "Epoch 5/200\n",
      "45/45 [==============================] - 512s 12s/step - loss: 0.0294 - accuracy: 0.9931 - val_loss: 3.1965 - val_accuracy: 0.6639\n",
      "Epoch 6/200\n",
      "45/45 [==============================] - 520s 12s/step - loss: 0.1182 - accuracy: 0.9721 - val_loss: 5.2245 - val_accuracy: 0.6694\n",
      "\n",
      "Epoch 00006: ReduceLROnPlateau reducing learning rate to 0.0003000000142492354.\n",
      "Epoch 7/200\n",
      "45/45 [==============================] - 476s 11s/step - loss: 0.0294 - accuracy: 0.9947 - val_loss: 1.0476 - val_accuracy: 0.8694\n",
      "Epoch 8/200\n",
      "45/45 [==============================] - 505s 11s/step - loss: 0.0024 - accuracy: 0.9992 - val_loss: 0.3794 - val_accuracy: 0.9000\n",
      "Epoch 9/200\n",
      "45/45 [==============================] - 517s 12s/step - loss: 0.0038 - accuracy: 0.9978 - val_loss: 0.3439 - val_accuracy: 0.9167\n",
      "Epoch 10/200\n",
      "45/45 [==============================] - 502s 11s/step - loss: 0.0016 - accuracy: 0.9993 - val_loss: 0.2952 - val_accuracy: 0.9222\n",
      "Epoch 11/200\n",
      "45/45 [==============================] - 511s 12s/step - loss: 8.4434e-04 - accuracy: 1.0000 - val_loss: 0.2721 - val_accuracy: 0.9194\n",
      "Epoch 12/200\n",
      "45/45 [==============================] - 275s 6s/step - loss: 0.0013 - accuracy: 0.9994 - val_loss: 0.2417 - val_accuracy: 0.9222\n",
      "Epoch 13/200\n",
      "45/45 [==============================] - 248s 6s/step - loss: 7.5516e-04 - accuracy: 1.0000 - val_loss: 0.1869 - val_accuracy: 0.9222\n",
      "\n",
      "Epoch 00013: ReduceLROnPlateau reducing learning rate to 9.000000427477062e-05.\n",
      "Epoch 14/200\n",
      "45/45 [==============================] - 248s 6s/step - loss: 4.8178e-04 - accuracy: 1.0000 - val_loss: 0.1974 - val_accuracy: 0.9194\n",
      "Epoch 15/200\n",
      "45/45 [==============================] - 247s 6s/step - loss: 2.4921e-04 - accuracy: 1.0000 - val_loss: 0.1746 - val_accuracy: 0.9361\n",
      "Epoch 16/200\n",
      "45/45 [==============================] - 247s 6s/step - loss: 1.6172e-04 - accuracy: 1.0000 - val_loss: 0.1829 - val_accuracy: 0.9250\n",
      "Epoch 17/200\n",
      "45/45 [==============================] - 244s 5s/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.2261 - val_accuracy: 0.9222\n",
      "Epoch 18/200\n",
      "45/45 [==============================] - 246s 6s/step - loss: 2.4255e-04 - accuracy: 1.0000 - val_loss: 0.2295 - val_accuracy: 0.9222\n",
      "\n",
      "Epoch 00018: ReduceLROnPlateau reducing learning rate to 2.700000040931627e-05.\n",
      "Epoch 19/200\n",
      "45/45 [==============================] - 244s 5s/step - loss: 2.2166e-04 - accuracy: 1.0000 - val_loss: 0.1921 - val_accuracy: 0.9278\n",
      "Epoch 20/200\n",
      "45/45 [==============================] - 245s 5s/step - loss: 1.4923e-04 - accuracy: 1.0000 - val_loss: 0.2200 - val_accuracy: 0.9250\n",
      "Epoch 21/200\n",
      "45/45 [==============================] - 243s 5s/step - loss: 4.6071e-04 - accuracy: 1.0000 - val_loss: 0.2452 - val_accuracy: 0.9194\n",
      "\n",
      "Epoch 00021: ReduceLROnPlateau reducing learning rate to 8.100000013655517e-06.\n",
      "Epoch 22/200\n",
      "45/45 [==============================] - 246s 6s/step - loss: 6.4173e-04 - accuracy: 0.9997 - val_loss: 0.2127 - val_accuracy: 0.9222\n",
      "Epoch 23/200\n",
      "45/45 [==============================] - 245s 5s/step - loss: 1.3142e-04 - accuracy: 1.0000 - val_loss: 0.2082 - val_accuracy: 0.9278\n",
      "Epoch 24/200\n",
      "45/45 [==============================] - 243s 5s/step - loss: 1.4546e-04 - accuracy: 1.0000 - val_loss: 0.2253 - val_accuracy: 0.9250\n",
      "\n",
      "Epoch 00024: ReduceLROnPlateau reducing learning rate to 2.429999949526973e-06.\n",
      "Epoch 25/200\n",
      "45/45 [==============================] - 246s 6s/step - loss: 2.2040e-04 - accuracy: 1.0000 - val_loss: 0.2308 - val_accuracy: 0.9222\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00025: early stopping\n"
     ]
    }
   ],
   "source": [
    "history3 = model3.fit_generator(train_data_gen, validation_data=val_data_gen, epochs=200, steps_per_epoch=len(train_data_gen), validation_steps=len(val_data_gen),callbacks=[learning_rate_reduction, early_stop],)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model3.save('xception.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "xec_acc = history3.history[\"val_accuracy\"]\n",
    "#xec_prec = history3.history[\"val_precision_m\"]\n",
    "#xec_rec = history3.history[\"val_recall_m\"]\n",
    "#xec_f1 = history3.history[\"val_f1_m\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(2, 1)\n",
    "ax1.plot(history3.history[\"loss\"], color=\"b\", label=\"Training loss\")\n",
    "ax1.plot(history3.history[\"val_loss\"], color=\"r\", label=\"validation loss\")\n",
    "ax1.legend()\n",
    "\n",
    "ax2.plot(history3.history[\"accuracy\"], color=\"b\", label=\"Training accuracy\")\n",
    "ax2.plot(history3.history[\"val_accuracy\"], color=\"r\", label=\"Validation accuracy\")\n",
    "ax2.legend()\n",
    "\n",
    "legend = plt.legend(loc=\"best\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Xception + MobileNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.layers import Average\n",
    "import efficientnet.keras \n",
    "def ensemble():\n",
    "\n",
    "    model_1 = load_model('mobilenet.h5', compile=False)\n",
    "    model_1 = Model(inputs = model_1.inputs, outputs = model_1.outputs, name = 'MobileNet')\n",
    "\n",
    "    model_2 = load_model('xception.h5', compile=False)\n",
    "    model_2 = Model(inputs = model_2.inputs, outputs = model_2.outputs, name = 'Xception')\n",
    "\n",
    "\n",
    "    models = [model_1, model_2]\n",
    "\n",
    "\n",
    "    models_input = Input(shape =(128,128,3))\n",
    "    models_output = [model(models_input) for model in models]\n",
    "    \n",
    "    ensemble_output = Average()(models_output)\n",
    "\n",
    "    simple_average = Model(inputs = models_input, outputs = ensemble_output, name = 'Ensemble')\n",
    "\n",
    "    return simple_average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"Ensemble\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "Total params: 24,127,212\n",
      "Trainable params: 24,050,796\n",
      "Non-trainable params: 76,416\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = ensemble()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss = keras.losses.categorical_crossentropy, optimizer= 'adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "45/45 [==============================] - 268s 6s/step - loss: 0.6270 - accuracy: 0.5558 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 2/200\n",
      "45/45 [==============================] - 258s 6s/step - loss: 0.6931 - accuracy: 0.4993 - val_loss: 0.6931 - val_accuracy: 0.5167\n",
      "Epoch 3/200\n",
      "45/45 [==============================] - 260s 6s/step - loss: 0.6931 - accuracy: 0.5170 - val_loss: 0.6931 - val_accuracy: 0.4806\n",
      "Epoch 4/200\n",
      "45/45 [==============================] - 258s 6s/step - loss: 0.6931 - accuracy: 0.4897 - val_loss: 0.6931 - val_accuracy: 0.5083\n",
      "Epoch 5/200\n",
      "45/45 [==============================] - 261s 6s/step - loss: 0.6931 - accuracy: 0.5155 - val_loss: 0.6931 - val_accuracy: 0.4667\n",
      "\n",
      "Epoch 00005: ReduceLROnPlateau reducing learning rate to 0.0003000000142492354.\n",
      "Epoch 6/200\n",
      "45/45 [==============================] - 259s 6s/step - loss: 0.6931 - accuracy: 0.5043 - val_loss: 0.6931 - val_accuracy: 0.5111\n",
      "Epoch 7/200\n",
      "45/45 [==============================] - 259s 6s/step - loss: 0.6931 - accuracy: 0.5164 - val_loss: 0.6931 - val_accuracy: 0.5056\n",
      "Epoch 8/200\n",
      "45/45 [==============================] - 261s 6s/step - loss: 0.6931 - accuracy: 0.4979 - val_loss: 0.6931 - val_accuracy: 0.4861\n",
      "\n",
      "Epoch 00008: ReduceLROnPlateau reducing learning rate to 9.000000427477062e-05.\n",
      "Epoch 9/200\n",
      "45/45 [==============================] - 259s 6s/step - loss: 0.6931 - accuracy: 0.5161 - val_loss: 0.6931 - val_accuracy: 0.5111\n",
      "Epoch 10/200\n",
      "45/45 [==============================] - 260s 6s/step - loss: 0.6931 - accuracy: 0.4962 - val_loss: 0.6931 - val_accuracy: 0.4972\n",
      "Epoch 11/200\n",
      "45/45 [==============================] - 258s 6s/step - loss: 0.6931 - accuracy: 0.5068 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "\n",
      "Epoch 00011: ReduceLROnPlateau reducing learning rate to 2.700000040931627e-05.\n",
      "Epoch 12/200\n",
      "45/45 [==============================] - 260s 6s/step - loss: 0.6931 - accuracy: 0.4843 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00012: early stopping\n"
     ]
    }
   ],
   "source": [
    "hist = model.fit_generator(train_data_gen, validation_data=val_data_gen, epochs=200, steps_per_epoch=len(train_data_gen), validation_steps=len(val_data_gen),callbacks=[learning_rate_reduction, early_stop],)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
